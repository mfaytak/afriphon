<?xml version="1.0" encoding="utf-8"?>

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"

 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/solid.css" integrity="sha384-VGP9aw4WtGH/uPAOseYxZ+Vz/vaTb1ehm1bwx92Fm8dTrE+3boLfF1SpAtB1z7HW" crossorigin="anonymous">

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/fontawesome.css" integrity="sha384-1rquJLNOM3ijoueaaeS5m+McXPJCGdr5HcA03/VHXxcp2kX2sUrQDmFc3jR5i/C7" crossorigin="anonymous">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

  <meta http-equiv="Content-Style-Type" content="text/css" />

  <meta name="generator" content="pandoc" />

  <meta name="author" content="Matthew Faytak, LLACAN" />

  <title>Practical field phonetics I</title>

  <style type="text/css">

    code{white-space: pre-wrap;}

    span.smallcaps{font-variant: small-caps;}

    div.columns{display: flex; gap: min(4vw, 1.5em);}

    div.column{flex: auto; overflow-x: auto;}

    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}

    /* The extra [class] is a hack that increases specificity enough to

       override a similar rule in reveal.js */

    ul.task-list[class]{list-style: none;}

    ul.task-list li input[type="checkbox"] {

      font-size: inherit;

      width: 0.8em;

      margin: 0 0.8em 0.2em -1.6em;

      vertical-align: middle;

    }

    .display.math{display: block; text-align: center; margin: 0.5rem auto;}

  </style>

  <link rel="stylesheet" type="text/css" media="screen, projection, print"

    href="assets/styles/slidy.css" />

  <script src="assets/scripts/slidy.js"

    charset="utf-8" type="text/javascript"></script>

</head>

<body>

<div class="slide titlepage">

  <h1 class="title">Practical field phonetics I</h1>

  <p class="author">

Matthew Faytak, LLACAN

  </p>

  <p class="date">4-5 June 2025</p>

</div>

<div id="overview-day-1" class="slide section level2">

<h1>Overview, day 1</h1>

<p>Day 1 of the workshop is broadly focused on recording and collection

of acoustic data, within instrumental phonetics</p>

<ul>

<li>Overview - why phonetics?</li>

<li>Optimizing recording conditions</li>

<li>Equipment</li>

<li>Better audio corpora from elicitation</li>

<li>Designing (somewhat) controlled production studies</li>

</ul>

<p>The “practical” element in this discussion: taking part in phonetic

work is not entirely about analysis; <strong>design</strong> and

<strong>planning</strong> are also crucial, and cost us nothing</p>

</div>

<div id="about-the-slides" class="slide section level2">

<h1>About the slides</h1>

<p>These slides are a <strong>web page</strong>; this slideshow’s URL is

<a href="https://mfaytak.github.io/afriphon/fieldphon-1.html">mfaytak.github.io/afriphon/fieldphon-1.html</a></p>

<ul>

<li>Use right, left arrow keys to navigate (or click to advance)</li>

<li>Press “A” to see all slides at once, and “A” again to go back to

slide view</li>

<li>Links are formatted like

<a href="https://www.youtube.com/watch?v=eVaUDAqrpKk">this</a></li>

<li>References look like <span class="cite">This (1985)</span></li>

<li>All references have links provided in the bibliography</li>

</ul>

<p>The slides are hosted

<a href="https://github.com/mfaytak/afriphon">here</a> on GitHub</p>

<p>References mentioned during the workshop are <strong>linked</strong>

at the end of the slides</p>

</div>

<div id="context-of-the-workshop"

class="title-slide slide section level1">

<h1>Context of the workshop</h1>



</div>

<div id="the-situation" class="slide section level2">

<h1>The situation</h1>

<p>Africa has long been regarded as central to phonetic description

<span class="cite">Ladefoged (1968), Maddieson &amp; Sands

(2019)</span></p>

<ul>

<li>Complex tone systems of various types abound</li>

<li>Clicks and tongue root harmony are found virtually nowhere else in

the world</li>

<li>Most African languages remain phonetically undocumented <span

class="cite">Whalen, DiCanio, &amp; Dockum (2019)</span></li>

</ul>

<p>Relatively little of this scholarship involves African scholars, an

issue we’ll revisit later</p>

</div>

<div id="long-term-goals" class="slide section level2">

<h1>Long-term goals</h1>

<p>Let’s assume that we are all committed to:</p>

<ul>

<li>Improving empirical <strong>coverage</strong> of African languages’

sound structures</li>

<li>Building data <strong>resources</strong> for African languages

<ul>

<li>Some data is better than no data</li>

<li>Crucial to advancing scientific research and technical

development</li>

</ul></li>

<li>Developing <strong>capacity</strong> for an African phonetics

practice,

<ul>

<li>Which is aapted to the needs and demands of fieldwork</li>

<li>Which can be adopted, in whole or in part, by researchers based on

the continent</li>

<li>Which is sensitive to the funding environment</li>

</ul></li>

</ul>

</div>

<div id="why-instrumental-phonetics" class="slide section level2">

<h1>Why instrumental phonetics?</h1>

<p>Several practical advantages over impressionistic approaches</p>

<ul>

<li><strong>Neutrality</strong> in the face of perceptual bias</li>

<li><strong>Precision</strong> and reliability in detecting

contrasts</li>

<li><strong>Community use</strong> of the created data</li>

</ul>

</div>

<div id="neutrality" class="slide section level2">

<h1>Neutrality</h1>

<p>Even a trained phonetic ear is prone to making occasional mistakes

based on <strong>perceptual bias</strong>: to assume you don’t make

these mistakes is to assume your ears are somehow different from

everyone else’s</p>

<ul>

<li>For example: nasal consonant codas are more often misidentified

after non-low vowels <span class="cite">Zee (1981)</span></li>

<li>Transcription mistakes permanently enter the record</li>

</ul>

<p><img src="./assets/media/zee.png" width="650"></p>

</div>

<div id="precision" class="slide section level2">

<h1>Precision</h1>

<p>Not all contrasts can be easily described by the analyst’s ear, and

especially transcribed quickly in the moment</p>

<ul>

<li>Fine vowel contrasts (especially central vowels)</li>

<li>Diphthongs versus consonant secondary articulation</li>

<li>Prenasalization versus N+C clusters</li>

<li>Subtle differences in tone level and contour</li>

<li>Multiple downsteps/upsteps</li>

</ul>

<p>Recordings allow for careful re-listening later</p>

</div>

<div id="community-use" class="slide section level2">

<h1>Community use</h1>

<p>Recordings are required for instrumental phonetic work, but there are

many benefits beyond this</p>

<ul>

<li>Speaker community may access the data if archived properly

<ul>

<li>Literacy development (teaching tools)</li>

<li>Technical development (speech resources)</li>

</ul></li>

<li>Community of scientific researchers may access the data

<ul>

<li>New analyses</li>

<li>Comparative work</li>

</ul></li>

<li>Analysis may be replicated later by other researchers (or the same

researchers)</li>

</ul>

</div>

<div id="complementary-methods" class="slide section level2">

<h1>Complementary methods</h1>

<p>The aim is not to <em>displace</em> impression-based methods, but to

<em>complement</em> them</p>

<ul>

<li>Transcription will always be needed at some level</li>

<li>Our point is that it should not be <em>exclusively</em> relied on as

the analytical object</li>

<li>When possible, transcriptions ought to be supplemented with

recordings, visualizations of recordings, or instrumental measures as

evidence</li>

<li>Instrumental measures as “second opinion” for analysis</li>

</ul>

</div>



<div id="audio-data-recording-conditions"

class="title-slide slide section level1">

<h1>Audio data: recording conditions</h1>



</div>

<div id="desired-qualities" class="slide section level2">

<h1>Desired qualities</h1>

<p>We always want acoustic speech data to be, to the extent

possible:</p>

<ul>

<li>Low in background <strong>noise</strong></li>

<li>Sufficiently <strong>loud</strong> against background noise, but not

too loud</li>

<li>Free of <strong>echo</strong></li>

</ul>

<p>Certain details of format are also important:</p>

<ul>

<li>Record using a high <strong>sampling rate</strong>, at least 22.1

kHz</li>

<li>Save in <strong>non-compressed</strong> format (such as

<strong>.WAV</strong>; avoid .MP3)</li>

</ul>

</div>

<div id="good-recording" class="slide section level2">

<h1>Good recording</h1>

<audio id="good" src="./assets/media/best-quality.wav">

</audio>

<button onclick="document.getElementById(&#39;good&#39;).play()">

“La plume de ma tante”

</button>

<ul>

<li>Speaker’s voice is much louder than background, but is not

<em>too</em> loud</li>

<li>Background is free of avoidable noise</li>

<li>Practically no echo</li>

</ul>

<p>The following slides contain recordings which fail on one of the

points above</p>

</div>

<div id="too-noisy" class="slide section level2">

<h1>Too noisy</h1>

<p>Recordings should not contain excessive background noise</p>

<audio id="noise2" src="./assets/media/noisy2.wav">

</audio>

<audio id="scuff" src="./assets/media/scuffing.wav">

</audio>

<ul>

<li><button onclick="document.getElementById(&#39;noise2&#39;).play()">

Continuous noise

</button>

from a fan</li>

<li><button onclick="document.getElementById(&#39;scuff&#39;).play()">

Intermittent noise

</button>

from touching the microphone</li>

</ul>

<p>Make test recordings! Any noise, however quiet to your ears in the

moment, will be <em>much louder</em> in the recording later</p>

<ul>

<li>Rain on the roof (especially metal roofs)</li>

<li>Appliances (refrigerators, any motors or fans)</li>

<li>Busy roads (trucks, taxis)</li>

<li>Chickens, goats, children, etc.</li>

<li>Phones ringing or vibrating</li>

<li>Speaker striking self, table, microphone, etc.</li>

</ul>

</div>

<div id="too-much-echo" class="slide section level2">

<h1>Too much echo</h1>

<audio id="echo1" src="./assets/media/echo1.wav">

</audio>

<audio id="echo2" src="./assets/media/echo2.wav">

</audio>

<p>If echo is strong, audio ends up overlapping itself; small problem

for listening but major problem for analysis later</p>

<ul>

<li><button onclick="document.getElementById(&#39;echo1&#39;).play()">

Slight echo

</button>

(in tiled hallway)</li>

<li><button onclick="document.getElementById(&#39;echo2&#39;).play()">

More echo

</button>

(in concrete stairwell)</li>

</ul>

<p>How to improve: listen for echo and choose surroundings which have

less</p>

<ul>

<li>“Soft” rooms reduce echo (couches, carpets, pillows, hanging

clothes); tile, stone, and cement produce echo</li>

<li>Record in the back seat of a car (motor off) if available</li>

<li>Record outside if no suitable room exists</li>

</ul>

</div>

<div id="too-loud-clipped" class="slide section level2">

<h1>Too loud (“clipped”)</h1>

<audio id="clip" src="./assets/media/clipping.wav">

</audio>

<audio id="pop" src="./assets/media/popping.wav">

</audio>

<p>If the speaker is too loud and/or too close to the microphone, the

device cannot respond enough; <strong>clipping</strong> results</p>

<ul>

<li><button onclick="document.getElementById(&#39;clip&#39;).play()">

Clipping of whole utterance

</button></li>

<li>This can also happen for

<button onclick="document.getElementById('pop').play()"> stops and

fricatives only</button>, where the releases “pop” in the

microphone</li>

</ul>

<p>How to improve: make test recordings, reposition microphones as

needed</p>

<ul>

<li>If there is general clipping, microphone needs to be further away or

speaker needs to be quieter</li>

<li>If stops “pop”, position microphone to the <strong>side</strong> of

the mouth</li>

<li><strong>Gain</strong> can often be adjusted if you are using a

recorder</li>

</ul>

</div>

<div id="recommendations-site-design" class="slide section level2">

<h1>Recommendations: site design</h1>

<p>Many of these characteristics are due to <strong>site

design</strong>; critical not just for data quality but

<strong>comparing</strong> your data to other data <span

class="cite">Faytak et al. under review</span></p>

<p>Design your site accordingly, and hold some things constant. To the

extent that you <em>can’t</em> hold any of these things constant, your

equipment may be able to compensate</p>

<ul>

<li>Keep space quiet and free of avoidable background noise</li>

<li>Limit access to the recording space to participants</li>

<li>Use a <em>consistent</em> recording space at “home base” if at all

possible

<ul>

<li>Reverberation and noise for a speaker seated in the space may affect

production <span class="cite">Bottalico et al., 2020; Hay et al.,

2017</span></li>

<li>Moving them to a <em>different location</em> in the space may affect

these characteristics</li>

</ul></li>

</ul>

</div>

<div id="recommendations-check-before-you-record"

class="slide section level2">

<h1>Recommendations: check before you record</h1>

<p>Once you have a setup you and your consultants are happy with, check

for problems <em>before</em> you record</p>

<ul>

<li>Make <strong>test recordings</strong> and <strong>check with

headphones</strong> to check for echo, gain problems, etc.</li>

</ul>

<p>Other fixes relate to the positioning of your equipment in the space,

regardless of what the equipment is: position microphones

appropriately</p>

</div>

<div id="recommendations-site-contents" class="slide section level2">

<h1>Recommendations: site contents</h1>

<p>Mind what, and who, is <em>in</em> the space when recording:</p>

<ul>

<li>Researchers present may <em>also</em> affect production due to

“audience design” <span class="cite">Bell, 1984; Hay et al., 2009;

Labov, 1991; Ameka, 2018</span></li>

<li>Social cues from local culture may be present in the data collection

space itself, and may affect language production as a function of the

participant’s social history <span class="cite">Hay and Drager, 2010;

Hurring et al., 2022</span></li>

</ul>

<p>So-called “Kangaroo/Kiwi priming” from Hay and Drager (2010):</p>

<p><img src="./assets/media/142-drager-nze.png" width="650"></p>

</div>



<div id="equipment" class="title-slide slide section level1">

<h1>Equipment</h1>



</div>

<div id="the-short-version" class="slide section level2">

<h1>The short version</h1>

<p>Use <strong>external microphones</strong>!</p>

<p><img src="./assets/media/zoom-good-bad.png" width="650"></p>

</div>

<div id="key-equipment" class="slide section level2">

<h1>Key equipment</h1>

<p>Most problems can be fixed by using the right <strong>external

microphone</strong>; catch less background echo/noise</p>

<ul>

<li>Look for <strong>cardioid</strong>, <strong>hypercardioid</strong>,

or <strong>unidirectional</strong> microphones for recording single

speakers</li>

<li><strong>Dynamic</strong> microphones are slightly more expensive,

but are less likely to clip than <strong>condenser</strong>

microphones</li>

<li><strong>Headset</strong> microphones are especially useful since

they point at the mouth and block out noise coming from other directions

<ul>

<li>If not suitable, <strong>shotgun</strong> microphones are a second

choice since they are usually cardioid in response</li>

</ul></li>

<li>Recording public events may require an

<strong>omnidirectional</strong> microphone</li>

<li>Position and distance of microphone(s) is also very important: avoid

clipping, pops, etc</li>

</ul>

<p>Checking your recording quality with <strong>headphones</strong> can

detect unanticipated issues</p>

</div>

<div id="optional-but-great-equipment" class="slide section level2">

<h1>Optional, but great, equipment</h1>

<p><strong>Acoustic baffles</strong> to reduce echo or wind noises</p>

<ul>

<li>Soft, fluffy objects around the room: blankets, sofas, etc.

<ul>

<li>Avoid hard, smooth surfaces</li>

<li>Cement, tile, plaster, etc are unfortunately extremely common in our

field environments</li>

</ul></li>

<li>A <strong>car</strong> with padded seats can function as a

soundbooth in a pinch (motor off, windows closed)</li>

<li>“Dead cats” and “marshmallows”: covers for mics which reduce

wind/airflow noise</li>

</ul>

<p>In many cases, <strong>quiet furniture</strong> can be gotten -

single-piece plastic chairs that will not creak or squeak</p>

</div>

<div id="sound-treatment" class="slide section level2">

<h1>Sound treatment</h1>

<p>Proper <strong>sound treatment</strong> is often possible in the

field with some improvisation. At my field site near Douala:</p>

<ul>

<li>Speakers sit facing a wall with added sound treatment</li>

<li>Locally convenient material is foam mattresses</li>

<li>Wooden frame constructed to stand one away from a wall</li>

<li>Chairs are “quiet” one-piece plastic chairs</li>

</ul>

<p><img src="./assets/media/soundproofing.jpeg" width="700"></p>

</div>

<div id="recommendations" class="slide section level2">

<h1>Recommendations:</h1>

<p>Use the <strong>same equipment in all sessions</strong> if at all

possible</p>

<ul>

<li>Different microphones and even different recorders are known to

affect fine details of recording <span class="cite">Vogel et al., 2014;

Sanker et al., 2021; Zhang et al., 2021</span></li>

<li>This has downstream effects on measures that might be taken <span

class="cite">Freeman and De Decker, 2021; Penney et al., 2021</span>

<ul>

<li>Basic acoustic measures are only slightly affected</li>

<li>But anything involving calculation of derived measures suffers

more</li>

</ul></li>

</ul>

<p>Equipment failures happen (in my experience, especially microphones);

try to replace with a comparable piece of equipment</p>

</div>



<div id="better-audio-from-elicitation"

class="title-slide slide section level1">

<h1>Better audio from elicitation</h1>



</div>

<div id="building-phonetics-corpora" class="slide section level2">

<h1>Building phonetics corpora</h1>

<p>We can build data sets suitable for phonetic analysis from

<em>recordings we already need to make</em>, if they are recorded

properly</p>

<ul>

<li>Attention to site design</li>

<li>Attention to recording equipment and settings</li>

<li>Some minor structural changes</li>

</ul>

<p>These do not require major changes to the work we already need to

do</p>

</div>

<div id="basic-improvements-to-recording-conditions"

class="slide section level2">

<h1>Basic improvements to recording conditions</h1>

<audio id="nsunsu" src="./assets/media/nsunsu.wav">

</audio>

<p>It is possible to get high-quality data in a field setting, with

relatively few adjustments to elicitation procedures! From my field

site, which we saw a few slides ago,</p>

<button onclick="document.getElementById(&#39;nsunsu&#39;).play()">

this text recording

</button>

<p><img src="./assets/media/nsunsu-waveform.png" width="700"></p>

<ul>

<li>Zoom H4 audio recorder (WAV, mono, 22.1 khZ sampling)</li>

<li>Shure SM10A hypercardioid headset microphone worn by speaker</li>

<li>Mattresses against the wall facing the speaker</li>

<li>Separate room with closed door (but open window)</li>

</ul>

</div>

<div id="no-improvements-to-conditions" class="slide section level2">

<h1>No improvements to conditions</h1>

<audio id="fang" src="./assets/media/fang.wav">

</audio>

<p>Nearly the same location but with setup with less careful choice of

equipment and fewer controls on nearby activities</p>

<button onclick="document.getElementById(&#39;fang&#39;).play()">

This elicitation recording

</button>

<p><img src="./assets/media/fang-waveform.png" width="700"></p>

<ul>

<li>Zoom H1 recorder (WAV, stereo, 48 kHz sampling)</li>

<li>No external microphone (H1’s internal omnidirectional mics

used)</li>

<li>No sound treatment - echo, rather extensive background noise

<ul>

<li>While it’s not always <em>this</em> bad, this level of noise applies

to a surprising portion of the materials</li>

<li>Recording possibly made in a common area or shared room rather than

a closed-off room</li>

</ul></li>

<li>Poor signal to noise ratio (note background “fuzz”)</li>

</ul>

<p>Data of this quality is archivable at ELAR, and frequently is

archived there!</p>

<ul>

<li>ELDP standards for recordings and recording equipment are <em>not

publicly defined</em> and seem excessively flexible</li>

<li>To my knowledge they also prioritize capturing a “scene” over

ensuring some minimum quality</li>

</ul>

</div>

<div id="the-myth-of-lab-quality" class="slide section level2">

<h1>The myth of “lab quality”</h1>

<p>“Phonetics requires lab data recorded in a sound booth, so why should

I even try?”</p>

<p>This is based on an unexamined <strong>myth</strong>: “the

laboratory” as an invariant gold standard <span class="cite">Latour,

1983; Banaji and Crowder, 1989; Speed et al., 2018; Whalen and

McDonough, 2015; Xu, 2010</span></p>

<ul>

<li>Labs <em>also</em> have different sources of unmanageable variation

in recording quality (background noise, etc)

<ul>

<li>Location near ducts, bathrooms</li>

<li>Low-frequency noise from the roof (in the case of my own

laboratory)</li>

</ul></li>

<li>Labs are constructed for different purposes/recording quality

standards, and according to different financial constraints</li>

</ul>

<p>Also, phonetics is not always as stringent as people imagine</p>

<ul>

<li>The field has somewhat loosened its recording quality standards for

interesting field data</li>

<li>Acknowledging that having more breadth means incorporating field

data</li>

</ul>

</div>



<div id="designing-more-controlled-studies"

class="title-slide slide section level1">

<h1>Designing more controlled studies</h1>



</div>

<div id="elicitation-vs.-controlled-study" class="slide section level2">

<h1>Elicitation vs. controlled study</h1>

<p>Elicitation:</p>

<ul>

<li>Speaker provides materials in a range of contexts</li>

<li>No special preparation required</li>

<li>Relatively spontaneous, uncontrolled speech</li>

<li>Plenty of confounds introduced</li>

</ul>

<p>Controlled <strong>production study</strong>:</p>

<ul>

<li>Speaker provides materials in a specific, pre-agreed context, a

<strong>frame sentence</strong></li>

<li>Preparation of a <strong>stimulus</strong> set and the frame is

required</li>

<li>Speakers have to be coached</li>

<li>Very few confounds</li>

</ul>

</div>

<div id="reasons-for-controlled-production"

class="slide section level2">

<h1>Reasons for controlled production</h1>

<p>If you are interested in some very fine phonetic detail, you cannot

reasonably expect to be able to observe that detail in uncontrolled,

spontaneous speech data: rather difficult to measure</p>

<ul>

<li>Phonation differences (modal vs. laryngealized vowels, voiced stops

vs. implosives, etc)</li>

<li>Timecourse differences (partially nasalized segments, etc)</li>

<li>Some durational differences (especially due to presence of other

segments, prosody, etc.)</li>

<li>Some vowel quality differences (ATR/RTR)</li>

</ul>

<p>The above is a non-exhaustive list; generally, <strong>anything

unclear or unfamiliar</strong>, or which you aren’t sure how to

characterize, should also be assumed to be like this</p>

<p>You may also not ever get <strong>enough</strong> “naturally

occurring” observations of some phenomena to make a clear judgment <span

class="cite">Xu, 2010</span></p>

</div>

<div id="controlled-elicitation" class="slide section level2">

<h1>“Controlled elicitation”</h1>

<p>With some slight adjustments to procedure, elicitation recordings can

compare favorably to a controlled study, and retain some of

elicitation’s advantages</p>

<ul>

<li>Saves time on designing a study, which might not be possible while

on a single field trip</li>

<li>Speakers are already familiar with elicitation and might not have

the same familiarity with controlled studies</li>

</ul>

</div>

<div id="a-basic-template" class="slide section level2">

<h1>A basic template</h1>

<p>The usual steps in elicitation:</p>

<ol style="list-style-type: decimal">

<li>Introduce the concept in the language of communication</li>

<li>Negotiate how many translations the concept has, and transcribe each

of them</li>

</ol>

<p>Add one more step:</p>

<ol start="3" style="list-style-type: decimal">

<li><strong>Controlled repetition</strong> phase for each agreed-upon

variant

<ul>

<li>Get <em>multiple repetitions</em> of each item, 3-5 minimally</li>

<li>Pauses between each repetition</li>

<li>Optionally, use a <strong>frame sentence</strong> to constrain the

surrounding prosodic details and keep the target items surrounded by

speech</li>

</ul></li>

</ol>

</div>

<div id="mundabli-ɲɔ-ⁿdʒaˤn" class="slide section level2">

<h1>Mundabli (ɲɔ᷆ ⁿdʒāˤn)</h1>

<p>A few recent studies of mine have been based on “controlled

elicitation” from 1000-item wordlist elicited from four Mundabli

speakers</p>

<ul>

<li>Thanks to Dwo Evette, Dwo Clifort, Ntambong Irene, Ntemfang

Ignatius, who requested acknowledgement</li>

<li>List developed in part by Nelson C. Tschonghongei (U. Yaoundé)

specifically for investigating northern Grassfields Bantu and Beboid

languages</li>

</ul>

<p>Mundabli is Yemne-Kimbi (Bantoid) language spoken in Lower Fungom,

Cameroon by ~800 people, now roughly half in diaspora in towns to the

west of Douala</p>

<p><img src="./assets/media/mundabli-map.png" width="800"></p>

</div>

<div id="research-question-1-high-vowels" class="slide section level2">

<h1>Research question 1: high vowels</h1>

<p>How does Mundabli (Yemne-Kimbi, Cameroon) distinguish its two sets of

high vowels? <span class="cite">Faytak et al. 2023</span></p>

<ul>

<li>Quite similar to the ear except for noisiness in higher vowels</li>

<li>Noisier <strong>[i]</strong>, <strong>[u]</strong> versus “lower”,

less noisy <strong>[ɪ]</strong>, <strong>[ʊ]</strong></li>

</ul>

<p><img src="./assets/media/mundabli-front.png" width="600">

<img src="./assets/media/mundabli-back.png" width="600"></p>

</div>

<div id="research-question-1-high-vowels-1"

class="slide section level2">

<h1>Research question 1: high vowels</h1>

<p>As it turns out: Mundabli seems to use frication as part of the

contrast; formants are not reliable to separate the vowels for 1/4

speakers and border on being unreliable for others</p>

<p><img src="./assets/media/mundabli-noiseresults1.png" width="500">

<img src="./assets/media/mundabli-noiseresults2.png" width="900"></p>

</div>

<div id="research-question-2-tone-and-onset-consonants"

class="slide section level2">

<h1>Research question 2: tone and onset consonants</h1>

<p>Is the pitch of Mundabli vowels affected by onset voicing, even with

the many tones in the language? <span class="cite">Yang &amp; Faytak

2025</span></p>

<ul>

<li>For theoretical reasons, we expect a language with a lot of tones

(high functional load) might <em>limit</em> the phonetic influence</li>

<li>Speakers have “phonetic knowledge” of language and plan accordingly

<span class="cite">Kingston &amp; Diehl 1994; Whalen 1990</span></li>

</ul>

<p>Mundabli contrasts numerous surface tones; some tone sandhi processes

and grammatical tone as well <span class="cite">Voll 2017</span></p>

<p><img src="./assets/media/mundabli-tones.png" width="800"></p>

</div>

<div id="research-question-2-tone-and-onset-consonants-1"

class="slide section level2">

<h1>Research question 2: tone and onset consonants</h1>

<p>As it turns out: no, Mundabli <strong>does not</strong> limit the

amount of pitch deviation that occurs when the syllable onset is a

voiceless obstruent</p>

<ul>

<li>Sample results shown for contour tones</li>

</ul>

<p><img src="./assets/media/mundabli-onsetf0.png" width="900"></p>

</div>

<div id="designing-a-controlled-production-study"

class="slide section level2">

<h1>Designing a controlled production study</h1>

<p>For a more precisely controlled study, the question is mainly of

<strong>planning</strong></p>

<ol style="list-style-type: decimal">

<li>Define your research question(s)</li>

<li>Determine how many experimental <strong>conditions</strong> you need

to answer the question(s)

<ul>

<li>Ensure you have a suitable <strong>control</strong></li>

</ul></li>

<li>Select stimuli around your conditions

<ul>

<li>Remove as many <strong>confounds</strong> as possible</li>

<li>Maximize word <strong>types</strong> and repetitions of

<strong>tokens</strong> within each condition</li>

</ul></li>

<li><strong>Test</strong> with multiple naïve speakers to check for

unsuitable stimuli or unexpected variability</li>

<li>Finally carry out the study (in the style of elicitation)</li>

</ol>

</div>

<div id="some-typical-research-questions" class="slide section level2">

<h1>Some typical research questions</h1>

<p>Field linguistics is most often concerned with confirming basic

characteristics of the language at issue; phonetics is no exception</p>

<ul>

<li>Does sound <strong>[A]</strong> have some specific acoustic or

articulatory characteristics?</li>

<li>What is the difference between <strong>[A]</strong> and

<strong>[B]</strong>?</li>

<li><em>Are</em> <strong>[A]</strong> and <strong>[B]</strong>

different?</li>

<li>How do speakers vary in producing <strong>[A]</strong> or

<strong>[B]</strong>?</li>

</ul>

</div>

<div id="confirmatory-vs.-exploratory-research"

class="slide section level2">

<h1>Confirmatory vs. exploratory research</h1>

<p>Basic distinction in the nature of research questions <span

class="cite">Roettger et al. 2019; Fife &amp; Rodgers 2022</span></p>

<ul>

<li><strong>Confirmatory</strong> research has specific hypotheses and

predictions formulated ahead of any observation</li>

<li><strong>Exploratory</strong> research does not (and often cannot)

make advance predictions</li>

</ul>

<p>Linguistics frequently suffers from trying to fit its work into a

confirmatory mold when this is not appropriate</p>

<ul>

<li>Often takes the form of <strong>HARKing</strong>: Hypothesizing

After Results are Known</li>

<li>Common problem in behavioral science due to perceived prestige of

confirmatory work</li>

</ul>

<p>It’s OK to be exploratory! <span class="cite">Tukey 1980</span></p>

<ul>

<li>Both are necessary parts of the scientific ecosystem, though they

are necessarily distributed differently around</li>

<li>Exploratory work can form a basis for later confirmatory work</li>

<li>Results on their own are useful without a hypothesis-shaped

justification invented after the fact</li>

</ul>

</div>

<div id="setting-up-conditions" class="slide section level2">

<h1>Setting up conditions</h1>

<p><strong>Condition</strong>: category grouping some types, or the

context they are produced in, which forms the basis for comparison in

analysis</p>

<p>In production experiments, conditions are often simply types of

segmental or prosodic <strong>context</strong>, including features that

are <strong>simultaneously produced</strong>, which we would expect to

induce coarticulation or coproduction</p>

<ul>

<li>Some segment (or class) adjacent to some segment (or class)</li>

<li>Tone or prosodic contrast produced simultaneously with some segment

(or class)</li>

<li>Some feature produced simultaneously with some collection of

features

<ul>

<li>e.g. nasalization or other secondary articulation on vowels versus

none</li>

<li>e.g. RTR vs. plain vowels</li>

<li>e.g. implosives vs. plain voiced stops (different laryngeal

features)</li>

</ul></li>

</ul>

<p><strong>Minimize</strong> number of conditions; fight the natural

urge to pose lots of small questions in one session by using lots of

conditions</p>

</div>

<div id="canon-of-structures" class="slide section level2">

<h1>“Canon” of structures</h1>

<p>You can also do full “documentation” of some phenomenon as it

intersects a variety of structures: very useful for exploratory work

when a language has an obviously interesting property which you don’t

fully understand yet</p>

<ul>

<li>All vowels, crossed with different coarticulating consonants</li>

<li>All tones crossed with onset consonant types</li>

<li>“Canon” of syllable types differing in some property

<ul>

<li>e.g. nasality on vowels resulting from NV(C), (C)VN, NVN, oral

controls …</li>

</ul></li>

<li>etc.</li>

</ul>

<p>Especially useful for more exploratory work in the field</p>

<ul>

<li>You may not even know what the interesting strcutures to zoom in on

are</li>

<li>So, recording all of them is a solution</li>

</ul>

</div>

<div id="canon-example-gbagyi" class="slide section level2">

<h1>“Canon” example: Gbagyi</h1>

<p>Gbagyi (Nupoid, Nigeria) has interesting syllable structure with

respect to nasality: good case study for collecting an entire “canon” of

items for later exploratory investigation</p>

<ul>

<li>Specific interest is in the realization of the

<strong>second</strong> syllable in each item</li>

<li>Design is broadly syllable nasality shape, crossed with vowel

quality, crossed with the consonant’s identity

<ul>

<li>Tone is largely uncontrolled</li>

</ul></li>

<li>Presentation of items below reflects Hyman &amp; Magaji (1970)

transcription, with <strong>[Cⁿ]</strong> indicating a nasal

release</li>

</ul>

<table>

<thead>

<tr>

<th></th>

<th>CV</th>

<th>CṼ</th>

<th>NV</th>

</tr>

</thead>

<tbody>

<tr>

<td>/i/</td>

<td>sātī ‘Saturday’</td>

<td>*</td>

<td></td>

</tr>

<tr>

<td></td>

<td>lāàdì ‘Sunday’</td>

<td>*</td>

<td>(āɲí ‘song’)</td>

</tr>

<tr>

<td>/a/</td>

<td>pūta᷆ ‘leg’</td>

<td>ótⁿá ‘next year’</td>

<td></td>

</tr>

<tr>

<td></td>

<td>òdā ‘father’</td>

<td>ōdⁿā ‘stream’</td>

<td>ōná ‘fire’</td>

</tr>

<tr>

<td>/u/</td>

<td>ɲātú ‘poison’</td>

<td>otⁿú ‘wood ash’</td>

<td></td>

</tr>

<tr>

<td></td>

<td>ōdú ‘heart’</td>

<td>òdⁿù ‘antelope’</td>

<td>kwánū ‘plate’</td>

</tr>

</tbody>

</table>

</div>

<div id="control-conditions" class="slide section level2">

<h1>Control conditions</h1>

<p>Analysis of phonetic data essentially always involves

<strong>comparisons</strong>; what we compare the condition of interest

to is quite important</p>

<p>Experimental comparisons between conditions must involve one or more

control conditions: the “absence of conditions”</p>

<ul>

<li>Most conditions can be thought of as “the presence of an

effect”</li>

<li>Control can be thought of as the absence of effects present in other

conditions</li>

</ul>

<p>Must compare control to at least one other non-control condition</p>

</div>

<div id="selecting-a-control" class="slide section level2">

<h1>Selecting a control</h1>

<p>Often requires some area knowledge to select properly:</p>

<ul>

<li>Onset consonants can perturb the pitch of vowels following (even in

tonal languages); “rise-fall dichotomy” <span class="cite">Hombert 1977,

1978; Gao &amp; Kirby 2024</span></li>

<li>Nasals are “neutral” compared to voiceless and voiced obstruents:

sonorants do not create any obstacles to the maintenance of voicing and

so don’t create pitch perturbations <span class="cite">Hanson 2009;

Kirby &amp; Ladd 2015</span></li>

<li>This was crucial to realizing that the size of the raising effect is

actually much larger, a finding that has now been replicated several

times <span class="cite">Hanson 2009; Kirby &amp; Ladd 2015; Yang &amp;

Faytak 2025</span></li>

</ul>

<p><img src="./assets/media/control-stops.png" width="650"></p>

</div>

<div id="choose-stimuli-based-on-conditions"

class="slide section level2">

<h1>Choose stimuli based on conditions</h1>

<p>Select lexical or phrase data to provide examples of each

condition</p>

<ul>

<li>I usually first do exploratory elicitation and transcribe</li>

<li>Then work from transcribed elicitation materials to design a more

controlled study if needed</li>

</ul>

<p>We have to distinguish <strong>types</strong> (the words used as

stimuli) from <strong>tokens</strong> (the actual instances of tokens

that are uttered): in general each type should have multiple tokens in a

study</p>

<ul>

<li>Maximize tokens per condition; also have more than one type per

condition (at least 2-3) due to needing to factor out word-specific

phonetics in modeling later on, which can include subtle effects of part

of speech <span class="cite">Gahl 2008, Lohmann 2018 </span>

<ul>

<li>The outcome for some category shouldn’t be driven by one

(potentially unusual) word, especially since in fieldwork it’s not

always possible to anticipate a word being unusual</li>

</ul></li>

<li>Get a few dozen tokens (or more) per condition if possible</li>

</ul>

</div>

<div id="remove-confounds" class="slide section level2">

<h1>Remove confounds</h1>

<p>Variation in context should generally be restricted in materials to

prevent <strong>confounds</strong> of the sort of variation or

difference being studied</p>

<p>Essentially, keep your items as close to minimal pairs as possible

(the motivations are basically the same)</p>

<ul>

<li>Segmental factors: surrounding consonants, vowels</li>

<li>Suprasegmental/prosodic factors: surface or underlying tone,

prominence</li>

<li>Word boundaries and other similar morphological boundaries</li>

</ul>

<p>Sometimes, it’s not entirely possible to perfectly control for

various confounds; in these cases you might <strong>balance</strong> for

variables that might influence your results, so that you can see them

“colored” by each value across the board</p>

<ul>

<li>i.e. if you cannot find lexical items which are tightly controlled

for consonant place, then vary the consonant so that each condition has

consonants of several places, <em>evenly distributed</em></li>

<li>Often assumed you will model the effect later and “factor it

out”</li>

</ul>

</div>

<div id="presentation-and-execution" class="slide section level2">

<h1>Presentation and execution</h1>

<p>Designed production studies can be carried out in the same way as

elicitation:</p>

<ul>

<li>Set up recording using the methods mentioned earlier</li>

<li>Prompt speaker to produce a type</li>

<li>Request multiple tokens after confirming the translation of the

type</li>

</ul>

<p>Keep the list the same across speakers to the extent possible, but

randomize the order</p>

<ul>

<li>The study’s questions, conditions, etc. should not be obvious to

speakers</li>

<li>Normal in field situations, especially for small languages, for

speakers to reject a few words</li>

<li>But don’t go too far: if every speaker produces completely different

words, it poses some problems for statistical modeling later on</li>

</ul>

</div>

<div id="controlled-study-mundabli-pharyngealized-vowels"

class="slide section level2">

<h1>Controlled study: Mundabli pharyngealized vowels</h1>

<p>More precisely designed study: how are Mundabli’s pharyngealized

vowels produced? <span class="cite">Faytak et al. 2024</span></p>

<p><img src="./assets/media/mundabli-inventory.png" width="800"></p>

<p>Two lexical items selected (based on elicited corpus) for each vowel

category, controlling onset consonant place</p>

<p><img src="./assets/media/mundabli-invtable.png" width="800"></p>

</div>

<div id="controlled-study-mundabli-pharyngealized-vowels-1"

class="slide section level2">

<h1>Controlled study: Mundabli pharyngealized vowels</h1>

<p>Some early findings from ongoing work:</p>

<ul>

<li>Centralizing effect on formants consistent with

pharyngealization</li>

<li>Not some other articulations like uvularization <span

class="cite">Evans et al. 2016</span></li>

</ul>

<p><img src="./assets/media/mundabli-f1f2.png" width="600"></p>

<ul>

<li>Voice quality differences are also observed: tenser or creakier

voice, which suggests lower vocal tract articulation is truly involved

<span class="cite">Edmondson et al 2007; Moisik et al. 2021</span></li>

</ul>

<p><img src="./assets/media/mundabli-vqgamms.png" width="800"></p>

<p>This leaves aside the articulatory component, which has been worked

out with ultrasound</p>

</div>

<div id="brainstorm-build-your-own" class="slide section level2">

<h1>Brainstorm: Build your own</h1>

<p>Let’s brainstorm a problem from a language of interest and

consier:</p>

<ul>

<li>What would your research question(s) be?</li>

<li>How would you design conditions and controls?</li>

<li>What confounds can be avoided, and which are unavoidable?</li>

<li>How would the typical presentation of the study work at your field

site?</li>

</ul>

</div>

<div id="references" class="slide section level2">

<h1>References</h1>

<p>Ameka, F. (2018). From comparative descriptive linguistic fieldwork

to documentary linguistic fieldwork in Ghana. University of Hawai’i

Press. http://hdl.handle.net/10125/24824</p>

<p>Banaji, M. R., and Crowder, R. G. (1989). The bankruptcy of everyday

memory. <em>American Psychologist</em>, 44(9), 1185–1193.

https://doi.org/10.1037/0003-066X.44.9.1185</p>

<p>Bell, A. (1984). Language Style as Audience Design. <em>Language in

Society</em>, 13(2), 145–204.</p>

<p>Bottalico, P., Codino, J., Cantor-Cutiva, L. C., Marks, K., Nudelman,

C. J., Skeffington, J., Shrivastav, R., Jackson-Menaldi, M. C., Hunter,

E. J., and Rubin, A. D. (2020). Reproducibility of Voice Parameters: The

Effect of Room Acoustics and Microphones. <em>Journal of Voice</em>,

34(3), 320–334. https://doi.org/10.1016/j.jvoice.2018.10.016</p>

<p>Edmondson, J. A., Padayodi, C. M., Hassan, Z. M., &amp; Esling, J. H.

(2007). The laryngeal articulator: Source and resonator. In J. Trouvain

&amp; W. J. Barry (Eds.), <em>Proc of the 16th International Congress of

Phonetic Sciences</em> (2065–2068). Saarbrücken, Germany.</p>

<p>Evans, J., Sun, J., Chiu, C., and Liou, M. (2016). Uvular

approximation as an articulatory vowel feature. <em>Journal of the

International Phonetic Association</em> 46(1), pp. 1–31.</p>

<p>Faytak, M., Shao, B., Douanla Taffre, A. and Tschonghongei, N.

(2023). Frication and formant frequencies in the Mundabli high vowels.

In <em>Proceedings of ICPhS 20</em>, Prague.</p>

<p>Faytak, M., Quintana Godoy, M., and Yang, T. (2024). Lingual and

epilaryngeal articulation of vowels in Mundabli. In <em>Proceedings of

ISSP 13</em>.</p>

<p>Faytak, M., Kadavá, Š., Xu, C., Özsoy, O., Akumbu, P., Cardoso, A.,

Amengual, M., Arvaniti, A., Belz, M., Bevivino, D., Casillas, J.,

Caudrelier, T., Ćwiek, A., Dokovova, M., Dutta, I., Egurtzegi, A.,

Forst, H., Foulkes, P., Garcia, R., Grice, M., Hanulíková, A., Hellmuth,

S., Kaźmierski, K., Li, X., Lorentzen, J., Mori, M., Nycz, J., Punnoose,

R., Quesada Vázquez, L., Rebernik, T., Sawicka-Stępińska, B., Sehyr, Z.,

Setter, J., Spaniol, M., Urrestarazu-Porta, I., Vella, A., Zhang, C.,

Zygis, M., Buchanan, E., and Roettger, T. (under review). Big Team

Science for language science: opportunities and challenges.

<em>Linguistics</em>.</p>

<p>Fife, D. A., &amp; Rodgers, J. L. (2022). Understanding the

exploratory/confirmatory data analysis continuum: Moving beyond the

“replication crisis”. <em>American Psychologist</em>, 77(3), 453.</p>

<p>Freeman, V., and De Decker, P. (2021). Remote sociophonetic data

collection: Vowels and nasalization from self‐recordings on personal

devices. <em>Language and Linguistics Compass</em>, 15(7), e12435.

https://doi.org/10.1111/lnc3.12435</p>

<p>Gahl, S. (2008). Time and thyme are not homophones: The effect of

lemma frequency on word durations in spontaneous speech.

<em>Language</em>, 84(3), 474-496.</p>

<p>Gao, J. and Kirby, J. (2024). Laryngeal contrast and sound change:

The production and perception of plosive voicing and co-intrinsic pitch.

<em>Language</em>, 100(1): 124–158.</p>

<p>Good, J., Lovegren, J., Mve, J. P., Nganguep Tchiemouo, C., Voll, R.,

&amp; Di Carlo, P. (2011). The languages of the Lower Fungom region of

Cameroon: Grammatical overview. <em>Africana Linguistica</em>, 17,

101-164.</p>

<p>Hanson, H. (2009). Effects of obstruent consonants on fundamental

frequency at vowel onset in English. <em>The Journal of the Acoustical

Society of America</em>, 125(1):425–441.</p>

<p>Hay, J., and Drager, K. (2010). Stuffed toys and speech perception.

<em>Linguistics</em>, 48(4). https://doi.org/10.1515/ling.2010.027</p>

<p>Hay, J., Drager, K., and Warren, P. (2009). Careful Who You Talk to:

An Effect of Experimenter Identity on the Production of the NEAR/SQUARE

Merger in New Zealand English. <em>Australian Journal of

Linguistics</em>, 29(2), 269–285.

https://doi.org/10.1080/07268600902823128</p>

<p>Hay, J., Podlubny, R., Drager, K., and McAuliffe, M. (2017).

Car-talk: Location-specific speech production and perception.

<em>Journal of Phonetics</em>, 65, 94–109.

https://doi.org/10.1016/j.wocn.2017.06.005</p>

<p>Hombert, J. (1977). Consonant Types, Vowel Height and Tone in Yoruba.

<em>Studies in African Linguistics</em>, 8(2): 173–190.</p>

<p>Hombert, J. (1978). Consonant types, vowel quality, and tone. In

Fromkin, V., ed, <em>Tone: A Linguistic Survey</em>: 77–111. Academic

Press, New York.</p>

<p>Hurring, G., Hay, J., Drager, K., Podlubny, R., Manhire, L., and

Ellis, A. (2022). Social Priming in Speech Perception: Revisiting

Kangaroo/Kiwi Priming in New Zealand English. <em>Brain Sciences</em>,

12(6), 684. https://doi.org/10.3390/brainsci12060684</p>

<p>Hyman, L. and Magaji, D. (1970). <em>Essentials of Gwari

Grammar.</em> Ibadan University Press.</p>

<p>Kingston, J., &amp; Diehl, R. L. (1994). Phonetic knowledge.

<em>Language</em>, 70(3), 419-454.</p>

<p>Kirby, J. and Ladd, D. (2015). Stop voicing and F0 perturbations:

Evidence from French and Italian. In <em>Proceedings of the ICPhS

18</em>, Glasgow.</p>

<p>Labov, W. (1991). <em>Sociolinguistic patterns</em>. Univ. of

Pennsylvania Press.</p>

<p>Ladefoged, P. (1968). <em>A phonetic study of West African languages:

An auditory-instrumental survey.</em> Cambridge University Press.</p>

<p>Latour, B. (1983). Give Me a Laboratory and I Will Raise the World.

In K. Knorr-Cetina and M. J. Mulkey (Eds.), <em>Science observed:

Perspectives on the social study of science</em> (pp. 141–170).

SAGE.</p>

<p>Lohmann, A. (2018). Cut (n) and cut (v) are not homophones: Lemma

frequency affects the duration of noun–verb conversion pairs.

<em>Journal of Linguistics</em>, 54(4), 753-777.</p>

<p>Maddieson, I. &amp; Sands, B. (2019). The sounds of the Bantu

languages. In Van de Velde, M., Bostoen, K., Nurse, D., &amp;

Philippson, G., eds., <em>The Bantu Languages: Second Edition</em>,

79-127. Routledge.

<a href="https://www.researchgate.net/profile/Bonny-Sands/publication/323369007_The_sounds_of_the_Bantu_languages/links/5a906c28aca2721405622bfb/The-sounds-of-the-Bantu-languages.pdf">Preprint

PDF</a></p>

<p>Moisik, S. R., Czaykowska-Higgins, E., &amp; Esling, J. H. (2021).

Phonological potentials and the lower vocal tract. <em>Journal of the

International Phonetic Association</em>, 51(1), 1-35.</p>

<p>Penney, J., Gibson, A., Cox, F., Proctor, M., and Szakay, A. (2021).

A Comparison of Acoustic Correlates of Voice Quality Across Different

Recording Devices: A Cautionary Tale. In <em>Proceedings of Interspeech

2021</em>, 1389–1393. https://doi.org/10.21437/Interspeech.2021-729</p>

<p>Roettger, T. B., Winter, B., &amp; Baayen, H. (2019). Emergent data

analysis in phonetic sciences: Towards pluralism and reproducibility.

<em>Journal of Phonetics</em>, 73, 1-7.</p>

<p>Sanker, C., Babinski, S., Burns, R., Evans, M., Johns, J., Kim, J.,

Smith, S., Weber, N., and Bowern, C. (2021). (Don’t) try this at home!

The effects of recording devices and software on phonetic analysis:

Supplementary material. <em>Language</em>, 97(4).

https://doi.org/10.1353/lan.2021.0079</p>

<p>Speed, L. J., Wnuk, E., and Majid, A. (2018). Studying

psycholinguistics out of the lab. In A. De Groot and P. Hagoort (Eds.),

<em>Research methods in psycholinguistics and the neurobiology of

language: A practical guide</em> (pp. 190–207). Wiley-Blackwell.</p>

<p>Tukey, J. W. (1980). We need both exploratory and confirmatory.

<em>The American Statistician</em>, 34(1), 23-25.</p>

<p>Voll, R. (2017). <em>A grammar of Mundabli: a Bantoid (Yemne-Kimbi)

language of Cameroon.</em> PhD dissertation, U of Leiden.</p>

<p>Vogel, A. P., Rosen, K. M., Morgan, A. T., and Reilly, S. (2014).

Comparability of Modern Recording Devices for Speech Analysis:

Smartphone, Landline, Laptop, and Hard Disc Recorder. <em>Folia

Phoniatrica et Logopaedica</em>, 66(6), 244–250.

https://doi.org/10.1159/000368227</p>

<p>Whalen, D. H. (1990). Coarticulation is largely planned. <em>Journal

of Phonetics</em>, 18(1), 3-35.</p>

<p>Whalen, D. H., and McDonough, J. (2015). Taking the Laboratory into

the Field. <em>Annual Review of Linguistics</em>, 1(1), 395–415.

https://doi.org/10.1146/annurev-linguist-030514-124915</p>

<p>Whalen, D. H., DiCanio, C., &amp; Dockum, R. (2020). Phonetic

documentation in three collections: Topics and evolution. <em>Journal of

the International Phonetic Association</em>, 52(1), 1-27.

<a href="https://doi.org/10.1017/S0025100320000079">Abstract</a></p>

<p>Xu, Y. (2010). In defense of lab speech. <em>Journal of

Phonetics</em>, 38(3), 329–336.

https://doi.org/10.1016/j.wocn.2010.04.003</p>

<p>Yang, T. and Faytak, M. (2025). Onset-tone interaction in Mundabli.

In <em>Proceedings of the Linguistic Society of America</em>, 10(1):

5895.</p>

<p>Zee, E. (1981). Effect of vowel quality on perception of post–vocalic

nasal consonants in noise. <em>Journal of Phonetics</em>, 9(1), 35-48.

<a href="https://doi.org/10.1016/S0095-4470(19)30925-8">Abstract</a></p>

<p>Zhang, C., Jepson, K., Lohfink, G., and Arvaniti, A. (2021).

Comparing acoustic analyses of speech data collected remotely. <em>The

Journal of the Acoustical Society of America</em>, 149(6), 3910–3916.

https://doi.org/10.1121/10.0005132</p>

</div>

</body>

</html>
