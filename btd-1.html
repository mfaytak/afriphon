<?xml version="1.0" encoding="utf-8"?>

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"

 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/solid.css" integrity="sha384-VGP9aw4WtGH/uPAOseYxZ+Vz/vaTb1ehm1bwx92Fm8dTrE+3boLfF1SpAtB1z7HW" crossorigin="anonymous">

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/fontawesome.css" integrity="sha384-1rquJLNOM3ijoueaaeS5m+McXPJCGdr5HcA03/VHXxcp2kX2sUrQDmFc3jR5i/C7" crossorigin="anonymous">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

  <meta http-equiv="Content-Style-Type" content="text/css" />

  <meta name="generator" content="pandoc" />

  <meta name="author" content="Banto1d, 23 March 2022" />

  <title>Practical and instrumental phonetics workshop</title>

  <style type="text/css">

      code{white-space: pre-wrap;}

      span.smallcaps{font-variant: small-caps;}

      span.underline{text-decoration: underline;}

      div.column{display: inline-block; vertical-align: top; width: 50%;}

  </style>

  <link rel="stylesheet" type="text/css" media="screen, projection, print"

    href="assets/styles/slidy.css" />

  <script src="assets/scripts/slidy.js"

    charset="utf-8" type="text/javascript"></script>

</head>

<body>

<div class="slide titlepage">

  <h1 class="title">Practical and instrumental phonetics workshop</h1>

  <p class="author">

Banto1d, 23 March 2022

  </p>

  <p class="date">Universität Hamburg<br/> Matthew Faytak<br/> Katie Franich</p>

</div>

<div id="overview" class="slide section level2">

<h1>Overview</h1>

<p>Part 1:</p>

<ul>

<li>Assumptions</li>

<li>Why (instrumental) phonetics?</li>

<li>Acoustic data</li>

<li>Using Praat</li>

</ul>

<p>Part 2:</p>

<ul>

<li>Types of measurements</li>

<li>Making figures</li>

<li>Numerical and tabular data</li>

</ul>

<p>Part 3:</p>

<ul>

<li>Beyond Praat: articulatory data</li>

<li>Practical considerations</li>

<li>Open discussion period</li>

</ul>

</div>

<div id="about-the-slides" class="slide section level2">

<h1>About the slides</h1>

<p>These slides are a <strong>web page</strong></p>

<ul>

<li>Use right, left arrow keys to navigate (or click to advance)</li>

<li>Press “A” to see all slides at once, and “A” again to go back to slide view</li>

<li>Links are formatted like <a href="https://www.youtube.com/watch?v=eVaUDAqrpKk">this</a></li>

<li>References look like <span class="cite">This (1985)</span></li>

<li>All references have links provided in the bibliography</li>

</ul>

<p>The slides are hosted <a href="https://github.com/mfaytak/afriphon">here</a> on GitHub</p>

<ul>

<li>Along with all associated media</li>

<li>This slideshow’s URL is <a href="https://mfaytak.github.io/afriphon/btd-1.html">mfaytak.github.io/afriphon/btd-1.html</a></li>

</ul>

</div>

<div id="references" class="slide section level2">

<h1>References</h1>

<p>Nearly all references mentioned during the workshop are <strong>linked</strong> at the end of the slides</p>

<ul>

<li>I have prioritized open-access materials as much as possible</li>

<li>I have aimed to include many “model papers”</li>

<li>Attendees are encouraged to look up these sources at the end and reinforce what they’ll learn today</li>

</ul>

</div>

<div id="some-assumptions" class="title-slide slide section level1"><h1>Some assumptions</h1></div><div id="the-situation" class="slide section level2">

<h1>The situation</h1>

<p>Africa has long been regarded as central to phonetic description <span class="cite">Ladefoged (1968), Maddieson &amp; Sands (2019)</span></p>

<ul>

<li>Complex tone systems abound</li>

<li>Clicks and tongue root harmony are found virtually nowhere else in the world</li>

<li>Most African languages remain phonetically undocumented <span class="cite">Whalen, DiCanio, &amp; Dockum (2019)</span></li>

</ul>

<p>But relatively little of this scholarship involves African scholars</p>

<ul>

<li>An issue we’ll revisit a few times</li>

</ul>

</div><div id="participants" class="slide section level2">

<h1>Participants</h1>

<p>We presume that you, the participants, are:</p>

<ul>

<li>Employed by, or trained at, a university on the African continent (sub-Sahara)</li>

<li>Researching in a low-resource context

<ul>

<li>External grants are uncommon</li>

<li>Institutional support is low</li>

</ul></li>

<li>Familiar with phonetics in theory, but not necessarily in practice</li>

</ul>

<p>If you are not in this group, we ask that you <strong>prioritize</strong> those in this group for questions and feedback</p>

</div><div id="all-of-us" class="slide section level2">

<h1>All of us</h1>

<p>Let’s assume that we are all committed to:</p>

<ul>

<li>Improving empirical <strong>coverage</strong> of African languages’ sound structures</li>

<li>Building speech data <strong>resources</strong> for African languages

<ul>

<li>Ethos: “some data is better than no data”</li>

<li>Important as starting point for technical development</li>

</ul></li>

<li>Developing <strong>capacity</strong> for an African phonetics practice</li>

<li>Doing these in a way which is adapted to local needs and demands</li>

</ul>

</div>

<div id="why-phonetics" class="title-slide slide section level1"><h1>Why phonetics?</h1></div><div id="definitions" class="slide section level2">

<h1>Definitions</h1>

<p>This workshop is an introduction to <strong>instrumental</strong> phonetics</p>

<ul>

<li>Relying on instrumental readouts for analysis</li>

<li>Not exclusively <strong>impressionistic</strong>: using the ear and transcribing speech sounds</li>

</ul>

<p>“Phonetic” work may also refer to non-contrastive <strong>subphonemic detail</strong></p>

<ul>

<li><em>The specific way</em> a phonemic contrast is produced</li>

<li>This is also important here, but we are focusing on instrumental methods</li>

</ul>

</div><div id="why-instrumental-phonetics" class="slide section level2">

<h1>Why instrumental phonetics?</h1>

<p>Several practical advantages over impressionistic approaches</p>

<ul>

<li><strong>Neutrality</strong> in the face of analytical and perceptual bias</li>

<li><strong>Precision</strong> and reliability in detecting contrasts</li>

<li><strong>Community use</strong> of the created data</li>

</ul>

</div><div id="neutrality" class="slide section level2">

<h1>Neutrality</h1>

<p>In impressionistic phonological description, all presentation of data is filtered through the worker’s theoretical analysis</p>

<ul>

<li>For example: autosegmental representations often make transcriptions more abstract <span class="cite">Hyman (2014):545</span></li>

</ul>

<p><img src="./assets/media/hyman-theory.png" width="700"></p>

<p>Phonetic recordings allow better testing of hypotheses about phonological structure</p>

<ul>

<li>Recordings do not intrinsically involve an analysis, and can be reanalyzed at a later date</li>

<li>Transcribed data (being analyzed) is much harder to use for this purpose</li>

</ul>

</div><div id="neutrality-1" class="slide section level2">

<h1>Neutrality</h1>

<p>Even a trained phonetic ear is prone to making occasional mistakes based on <strong>perceptual bias</strong></p>

<ul>

<li>For example: nasal consonant codas are more often misidentified after non-low vowels <span class="cite">Zee (1981)</span></li>

</ul>

<p><img src="./assets/media/zee.png" width="600"></p>

<ul>

<li>Transcription mistakes permanently enter the record</li>

</ul>

</div><div id="precision" class="slide section level2">

<h1>Precision</h1>

<p>Not all contrasts can be easily described by the analyst’s ear, especially in the moment</p>

<ul>

<li>Fine vowel contrasts (especially central vowels)</li>

<li>Diphthongs versus consonant secondary articulation</li>

<li>Prenasalization versus N+C clusters</li>

<li>Subtle differences in tone level and contour</li>

<li>Multiple downsteps/upsteps</li>

</ul>

<p>Recordings allow for careful listening later</p>

</div><div id="community-use" class="slide section level2">

<h1>Community use</h1>

<p>Recordings are required for instrumental phonetic work: many incidental benefits</p>

<ul>

<li>Speaker community may access the data

<ul>

<li>Literacy development (teaching tools)</li>

<li>Technical development (speech resources)</li>

</ul></li>

<li>Community of scientific researchers may access the data

<ul>

<li>New analyses</li>

<li>Comparative work</li>

</ul></li>

<li>Analysis may be replicated</li>

</ul>

</div><div id="complementary-methods" class="slide section level2">

<h1>Complementary methods</h1>

<p>The aim is not to <em>displace</em> impression-based methods, but to <em>complement</em> them</p>

<ul>

<li>Transcription will always be needed at some level</li>

<li>Our point is that it should not be <em>exclusively</em> relied on as the analytical object</li>

<li>Whenever possible, transcriptions ought to be supplemented with recordings, visualizations of recordings, or instrumental measures as evidence</li>

<li>Instrumental measures as “second opinion” for analysis</li>

</ul>

</div>

<div id="recording-acoustic-data" class="title-slide slide section level1"><h1>Recording acoustic data</h1></div><div id="desired-qualities" class="slide section level2">

<h1>Desired qualities</h1>

<p>We always want acoustic speech data to be:</p>

<ul>

<li>Low in background <strong>noise</strong></li>

<li>Sufficiently <strong>loud</strong> against background noise, but not too loud</li>

<li>Free of <strong>echo</strong></li>

</ul>

<p>Certain details of format are also important:</p>

<ul>

<li>Record using a high <strong>sampling rate</strong>, at least 22.1 kHz</li>

<li>Save in <strong>non-compressed</strong> format (such as <strong>.WAV</strong>; avoid .MP3)</li>

</ul>

</div><div id="good-recording" class="slide section level2">

<h1>Good recording</h1>

<audio id="good" src="./assets/media/best-quality.wav">

</audio>

<p>Here is an example of a good recording</p>

<ul>

<li><button onclick="document.getElementById(&#39;good&#39;).play()">

“La plume de ma tante”

</button></li>

<li>Speaker’s voice is much louder than background, but is not <em>too</em> loud</li>

<li>Background is free of avoidable noise</li>

<li>Practically no echo</li>

</ul>

<p>The following slides contain recordings which fail on one of the points above</p>

</div><div id="too-noisy" class="slide section level2">

<h1>Too noisy</h1>

<p>Recordings should not contain excessive background noise</p>

<audio id="noise2" src="./assets/media/noisy2.wav">

</audio>

<audio id="scuff" src="./assets/media/scuffing.wav">

</audio>

<ul>

<li><button onclick="document.getElementById(&#39;noise2&#39;).play()">

Continuous noise

</button>

from a fan</li>

<li><button onclick="document.getElementById(&#39;scuff&#39;).play()">

Intermittent noise

</button>

from touching the microphone</li>

</ul>

<p>Any noise, however quiet to your ears in the moment, will be much louder in the recording later</p>

</div><div id="how-to-improve" class="slide section level2">

<h1>How to improve</h1>

<p>Listen carefully to your surroundings, and avoid:</p>

<ul>

<li>Rain on the roof (especially metal roofs)</li>

<li>Appliances (refrigerators, any motors or fans)</li>

<li>Busy roads (trucks, taxis)</li>

<li>Chickens, goats, children, etc.</li>

</ul>

<p>Speaker should also minimize non-speech noise:</p>

<ul>

<li>Touching or scratching microphone, or contacting shirt collar</li>

<li>Producing background noises when emphatic (striking chest or table, clapping hands)</li>

<li>Phone ringing or vibrating</li>

</ul>

</div><div id="too-much-echo" class="slide section level2">

<h1>Too much echo</h1>

<audio id="echo1" src="./assets/media/echo1.wav">

</audio>

<audio id="echo2" src="./assets/media/echo2.wav">

</audio>

<p>If echo is strong, speech ends up overlapping itself; problem for listening and analysis later</p>

<ul>

<li><button onclick="document.getElementById(&#39;echo1&#39;).play()">

Slight echo

</button>

(in tiled hallway)</li>

<li><button onclick="document.getElementById(&#39;echo2&#39;).play()">

More echo

</button>

(in concrete stairwell)</li>

</ul>

<p>How to improve: listen for echo and choose surroundings which have less</p>

<ul>

<li>“Soft” rooms reduce echo (couches, carpets, pillows, hanging clothes); tile, stone, and cement produce echo</li>

<li>Record in the back seat of a car (motor off) if available</li>

<li>Record outside if no suitable room exists</li>

</ul>

</div><div id="too-loud-clipped" class="slide section level2">

<h1>Too loud (clipped)</h1>

<audio id="clip" src="./assets/media/clipping.wav">

</audio>

<audio id="pop" src="./assets/media/popping.wav">

</audio>

<p>If the speaker is too loud and/or too close to the microphone, the device cannot respond enough; <strong>clipping</strong> results</p>

<ul>

<li><button onclick="document.getElementById(&#39;clip&#39;).play()">

Clipping of whole utterance

</button></li>

<li>This can also happen for <button onclick="document.getElementById('pop').play()"> stops and fricatives only</button>, where the releases “pop” in the microphone</li>

</ul>

<p>How to improve: make test recordings after you position your microphones</p>

<ul>

<li>If there is general clipping, microphone needs to be further away or speaker needs to be quieter</li>

<li>If stops “pop”, position microphone to the side of the mouth</li>

<li><strong>Gain</strong> can often be adjusted if you are using a recorder</li>

</ul>

</div><div id="equipment" class="slide section level2">

<h1>Equipment</h1>

<p>Not much equipment required: something to make recordings on</p>

<ul>

<li>Laptop computer</li>

<li>Smartphone with recording app

<ul>

<li>“Awesome Voice Recorder X” (free with ads) is a good app</li>

<li>Others must definitely exist</li>

</ul></li>

<li>Hand recorder/memo recorder</li>

<li>Professional recorder (Zoom H4N, etc)</li>

</ul>

<p>A way of transferring files off of the device and storing for future analysis:</p>

<ul>

<li>SD card</li>

<li>USB drive or external drive</li>

</ul>

<p>Headphones, to check recording quality</p>

</div><div id="equipment-1" class="slide section level2">

<h1>Equipment</h1>

<p>External microphones can increase the quality of acoustic data by recording less echo and background noise</p>

<ul>

<li>Look for <strong>cardioid</strong> or <strong>unidirectional</strong> in the description if you are recording single speakers</li>

<li>Recording public events may require an <strong>omnidirectional</strong> microphone</li>

</ul>

<p>An acoustic baffle can reduce echo</p>

<ul>

<li>Soft, fluffy objects: blankets, sofas, etc.</li>

<li>This can also be achieved by selecting the recording setting carefully, and using a cardioid microphone</li>

</ul>

</div><div id="other-tips" class="slide section level2">

<h1>Other tips</h1>

<p>Do not use computer noise reduction/filtering in general</p>

<ul>

<li>Go into your computer’s sound settings and <em>turn this off</em>; make sure apps (i.e. Zoom) don’t have separate filters</li>

<li>Normal to hear slight “fuzz” in background, or very slight echo</li>

</ul>

<p>Recording over <strong>Zoom</strong> works surprisingly well, if all else fails <span class="cite">Ge, Mok, &amp; Xiong (2021); Sanker et al (2021)</span></p>

<ul>

<li>Some <em>small</em> effects on the recording are noted</li>

<li>Turn noise cancellation off if using to record (switch to “original sound”)</li>

<li>Better still to use the speaker’s phone on their end to record, and use Zoom to supervise the process</li>

</ul>

</div>

<div id="basic-praat-tutorial" class="title-slide slide section level1"><h1>Basic Praat (tutorial)</h1></div><div id="downloading-and-configuring" class="slide section level2">

<h1>Downloading and configuring</h1>

<p>Download Praat from <a href="https://fon.hum.uva.nl">fon.hum.uva.nl</a> or <a href="https://praat.org">praat.org</a></p>

<p><img src="./assets/media/praat1.png" width="800"></p>

<ul>

<li>Mac: the .dmg file contains Praat.app (which you can run immediately) and the option to install</li>

<li>If you have issues opening, see <a href="https://www.fon.hum.uva.nl/praat/download_mac.html">2. “How to Start”</a> here</li>

<li>Windows: the .zip file contains Praat.exe, which you simply double-click to run (instructions <a href="https://www.fon.hum.uva.nl/praat/download_win.html">here</a> if needed)</li>

</ul>

</div><div id="windows-and-manual" class="slide section level2">

<h1>Windows and manual</h1>

<p>Both the <strong>object window</strong> (shown below) and <strong>picture window</strong> appear when you open Praat (we’ll ignore the picture window for now)</p>

<p>Basic issues can often be solved using the manual</p>

<p><img src="./assets/media/praat-manual.png" width="400"> <img src="./assets/media/praat-manual-search.png" width="400"></p>

<ul>

<li>The manual is also available online <a href="https://www.fon.hum.uva.nl/praat/manual/Manual.html">here</a></li>

<li>Other introductory guides can be found <a href="https://www.fon.hum.uva.nl/praat/manualsByOthers.html">here</a></li>

</ul>

</div><div id="first-recording" class="slide section level2">

<h1>First recording</h1>

<p>Let’s record ourselves saying a “good day, good afternoon” greeting in whichever language you would like</p>

<p><img src="./assets/media/praat-record-menu.png" width="400"> <img src="./assets/media/praat-record-console.png" width="400"></p>

<ul>

<li>Make sure you “save to list” before closing the recorder!</li>

</ul>

</div><div id="stored-sound" class="slide section level2">

<h1>Stored sound</h1>

<p>You should now have a Sound in your <strong>objects</strong> window</p>

<ul>

<li>Select the Sound object and a menu will appear to the right</li>

<li>Click “Play” to hear your sound</li>

</ul>

<p><img src="./assets/media/praat-Sound.png" width="600"></p>

</div><div id="saving-your-recording" class="slide section level2">

<h1>Saving your recording</h1>

<p>We’ll end this by saving our work as a .WAV file (the standard format for phonetics work)</p>

<ul>

<li>The file is not yet saved, only <em>stored</em> in Praat</li>

<li>If you close Praat without saving the file, it will vanish</li>

</ul>

<p><img src="./assets/media/praat-save-Sound.png" width="600"></p>

</div><div id="importing-a-sound-file" class="slide section level2">

<h1>Importing a sound file</h1>

<audio id="bush" src="./assets/media/bbk-hills-of-bushes.wav">

</audio>

<p>We might also <strong>import</strong> sounds which have already been recorded</p>

<ul>

<li>Download <a href="./assets/media/bbk-files.zip">this ZIP file</a> (673 KB), which contains all of the files we’ll use</li>

<li>Use the “Open” dialogue to open <strong>bbk-hills-of-bushes.wav</strong></li>

<li>That file contains one utterance of Babanki <button onclick="document.getElementById('bush').play()"> [tə̀tāŋ tə́ tə́ꜜtóʔ]</button> “hills of bushes” <span class="cite">from Faytak &amp; Akumbu (2021)</span></li>

</ul>

<p><img src="./assets/media/praat-import.png" width="600"></p>

</div>

<div id="making-and-using-textgrids" class="title-slide slide section level1"><h1>Making and using TextGrids</h1></div><div id="viewing-a-sound-file" class="slide section level2">

<h1>Viewing a sound file</h1>

<p>We’ll start by viewing Babanki <button onclick="document.getElementById('bush').play()"> [tə̀tāŋ tə́ tə́ꜜtóʔ]</button> “hills of bushes”</p>

<ul>

<li>Select the Sound and click “View and Edit” in the right menu</li>

</ul>

<p>Viewer window has button and keyboard controls</p>

<ul>

<li>Select by clicking, SHIFT-clicking, or clicking and dragging in sound</li>

<li>Press TAB to play selected sound, or click bar below window</li>

<li>Control buttons (zoom in, zoom out, scroll) are at lower left</li>

<li>Keyboard shortcuts: CTRL+ (PC) or Command+ (Mac)…

<ul>

<li>A: zoom out to all</li>

<li>N: zoom to selection</li>

<li>I: zoom in</li>

<li>O: zoom out</li>

</ul></li>

</ul>

<p><img src="./assets/media/praat-bbk-open.png" width="700"></p>

<p>We may wish to know where the words and segments are, but we lack useful landmarks at this point</p>

<ul>

<li>Each “blob” is a syllable</li>

<li>No indication of tones (yet)</li>

</ul>

</div><div id="making-a-textgrid" class="slide section level2">

<h1>Making a TextGrid</h1>

<p><strong>TextGrids</strong> are one of the most useful features of Praat: annotate and organize your audio files</p>

<ul>

<li>Using the menu as shown below, we’ll make a TextGrid for our Babanki sound object</li>

</ul>

<p><img src="./assets/media/praat-annotate.png" width="400"> <img src="./assets/media/praat-make-tg.png" width="400"></p>

</div><div id="interval-tiers" class="slide section level2">

<h1>Interval tiers</h1>

<p>Let’s use the <strong>interval tier</strong> “sentence” and use it to transcribe the utterance</p>

<ul>

<li>Contains a list of ranges in time separated by boundaries</li>

<li>Useful for marking off words, utterances, and some vowels and consonants</li>

<li>Here, click before the beginning and after the end of the utterance, then type a transcription or translation in the middle</li>

</ul>

<p><img src="./assets/media/praat-bbk-interval.png" width="700"></p>

</div><div id="point-tiers" class="slide section level2">

<h1>Point tiers</h1>

<p>Let’s use the <strong>point tier</strong> “stop” to mark off where each [t] release happens</p>

<ul>

<li>Contains a list of points in time</li>

<li>Useful for instantaneous events</li>

<li>Note that <em>intervals are generally more useful</em> for most segments</li>

<li>Can’t click and highlight range like interval tier</li>

</ul>

<p><img src="./assets/media/praat-bbk-point.png" width="700"></p>

</div><div id="adding-and-removing-tiers" class="slide section level2">

<h1>Adding and removing tiers</h1>

<p>We might be dissatisfied with how the tone marks are displaying; we could make a new tier for tones (autosegmental style)</p>

<p><img src="./assets/media/praat-bbk-add.png" width="400"> <img src="./assets/media/praat-bbk-add2.png" width="300"></p>

<p>Amending the TextGrid using the new tier:</p>

<p><img src="./assets/media/praat-bbk-add3.png" width="700"></p>

</div><div id="saving-textgrids" class="slide section level2">

<h1>Saving TextGrids</h1>

<p>Using CTRL+S or the menu shown below, you must <em>save</em> your TextGrid when you are done</p>

<ul>

<li>If you close Praat without saving your TextGrid, it will vanish</li>

<li>Much like recorded audio files which are stored in the object list</li>

</ul>

<p><img src="./assets/media/praat-tg-save.png" width="700"></p>

</div>

<div id="reading-our-data" class="title-slide slide section level1"><h1>Reading our data</h1></div><div id="data-displays" class="slide section level2">

<h1>Data displays</h1>

<p>We may wish to provide further details in our TextGrids, but we encounter another problem here: how to interpret the data?</p>

<ul>

<li>Praat shows <strong>waveforms</strong> and <strong>spectrograms</strong></li>

<li>Note the simpler TextGrid (segments, tones); <strong>bbk-hills-of-bushes.TextGrid</strong> in downloaded files</li>

</ul>

<p><img src="./assets/media/praat-bbk-datatypes.png" width="700"></p>

</div><div id="waveforms" class="slide section level2">

<h1>Waveforms</h1>

<p><strong>Waveforms</strong> show sound pressure (the pressure that sound waves make on the microphone) versus time</p>

<ul>

<li>We expect any <strong>voiced</strong> speech signal to <em>oscillate</em> because the vocal folds open and close in a repeating pattern</li>

<li>Other <strong>voiceless</strong> sounds show no movement away from “zero line” and no clear oscillation</li>

</ul>

<p><img src="./assets/media/praat-bbk-periodicity.png" width="700"></p>

</div><div id="sonority" class="slide section level2">

<h1>Sonority</h1>

<p>Sounds produced with a more open mouth are <em>louder</em> and more sonorous <span class="cite">Parker (2008) </span>; these are <em>thicker</em> on the waveform</p>

<p><img src="./assets/media/praat-bbk-sonority.png" width="700"></p>

</div><div id="spectrograms" class="slide section level2">

<h1>Spectrograms</h1>

<p>We can also show the <strong>spectrogram</strong> for our recording</p>

<ul>

<li>Breaks down our waveform to give us information about the <strong>sound spectrum</strong> and where its energy is (high or low frequency)</li>

</ul>

<p>Spectrograms are three-dimensional, and show time vs. <strong>frequency</strong> vs. sound pressure (color)</p>

<ul>

<li>The darker the spectrogram (and the thicker the waveform), the more sound pressure there is</li>

</ul>

<p><img src="./assets/media/praat-bbk-spectro0.png" width="700"></p>

<ul>

<li>Think of it as an elevation map (Mt. Cameroon pictured)</li>

</ul>

<p><img src="./assets/media/relief-map.png" width="400"></p>

</div><div id="interpreting-spectrograms" class="slide section level2">

<h1>Interpreting spectrograms</h1>

<p><strong>Vowels</strong>, <strong>semivowels</strong>, and <strong>approximants</strong> have characteristic striping, horizontally and vertically</p>

<ul>

<li>Voicing is visible as vertical stripes in vowels, and as a small “bar” at bottom</li>

<li><strong>Formants</strong> are clear horizontal bands above the voicing bar</li>

</ul>

<p><img src="./assets/media/praat-bbk-spectro1.png" width="700"></p>

</div><div id="interpreting-spectrograms-1" class="slide section level2">

<h1>Interpreting spectrograms</h1>

<p><strong>Nasals</strong> look somewhat like vowels, with “smudged” formants and less energy (darkness)</p>

<ul>

<li>Due to the opening of the velum: nasal cavity “muffles” the sound</li>

<li>Much like soft objects in a room muffle echo</li>

</ul>

<p><img src="./assets/media/praat-bbk-spectro2.png" width="700"></p>

</div><div id="interpreting-spectrograms-2" class="slide section level2">

<h1>Interpreting spectrograms</h1>

<p><strong>Fricatives</strong> have high-frequency or low-frequency noise</p>

<ul>

<li>Dark irregular smudges across entire areas of spectrogram</li>

<li>The further back the fricative, the lower the average frequency</li>

<li>Compare [s] and [ʒ]: [s] is further front, has higher frequency, sits higher on spectrogram</li>

</ul>

<p><img src="./assets/media/praat-fricative1.png" width="700"></p>

<p><img src="./assets/media/praat-fricative2.png" width="700"></p>

</div><div id="interpreting-spectrograms-3" class="slide section level2">

<h1>Interpreting spectrograms</h1>

<p><strong>Stops</strong> show an absence of (most) energy followed by a <strong>burst</strong> across the whole spectrum</p>

<p><img src="./assets/media/praat-bbk-stop1.png" width="700"></p>

<p><strong>Affricates</strong> look similar, but as if they were followed by a fricative</p>

<ul>

<li>From Babanki [kə̀dʒóm] ‘Babanki’ <span class="cite">Faytak &amp; Akumbu (2021)</span></li>

</ul>

<p><img src="./assets/media/praat-bbk-stop2.png" width="700"></p>

</div><div id="prenasalized-segments" class="slide section level2">

<h1>Prenasalized segments</h1>

<p>Prenasalized stops and affricates often have a <em>long nasal closure</em> followed by a <em>short oral closure</em> which we can see clearly in the spectrogram</p>

<ul>

<li>Note the “smudged” energy goes away when oral closure begins in [ⁿpfʲ] below</li>

<li>From Babanki [kə̀ⁿpfʲɨ́ŋ] ‘owl’ <span class="cite">Faytak &amp; Akumbu (2021)</span></li>

</ul>

<p><img src="./assets/media/praat-bbk-stop3.png" width="700"></p>

</div>

<div id="drawing-figures" class="title-slide slide section level1"><h1>Drawing figures</h1></div><div id="why-make-figures" class="slide section level2">

<h1>Why make figures?</h1>

<p>Figures are an easy way to present a small amount of phonetic data in scientific papers</p>

<ul>

<li>Give support to phonological judgments</li>

<li>Support particular transcriptions</li>

<li>Provide more detail for any especially unusual sounds or sound contrasts</li>

</ul>

<p>This section: professional-looking and informative data displays</p>

</div><div id="picture-window" class="slide section level2">

<h1>Picture window</h1>

<p>Waveforms and spectrograms can be “drawn” or “painted” (respectively) in the <strong>picture window</strong></p>

<ul>

<li>This also opened when you open Praat; we’ll stop ignoring it now</li>

<li>The blue rectangle indicates the <em>plot area</em> where the figure will be drawn: change size by clicking and dragging as needed</li>

</ul>

<p><img src="./assets/media/praat-picture.png" width="600"></p>

</div><div id="drawing-a-waveform" class="slide section level2">

<h1>Drawing a waveform</h1>

<p>“Draw” (in the object window) is for any line-based drawings, including waveforms</p>

<ul>

<li>Select a Sound to draw its waveform</li>

</ul>

<p><img src="./assets/media/praat-bbk-draw.png" width="400"> <img src="./assets/media/praat-draw-options.png" width="500"></p>

<p>The result: a waveform drawn within the plot area</p>

<p><img src="./assets/media/praat-drawn.png" width="600"></p>

</div><div id="drawing-a-textgrid" class="slide section level2">

<h1>Drawing a TextGrid</h1>

<p>TextGrids can be drawn as well, using the same menu as Sounds</p>

<ul>

<li>By default, they appear with an empty space above them</li>

</ul>

<p><img src="./assets/media/praat-drawn-tg.png" width="700"></p>

</div><div id="combining-textgrids-and-waveforms" class="slide section level2">

<h1>Combining TextGrids and waveforms</h1>

<p>A Sound and TextGrid can be drawn together very easily: simply <strong>select both</strong> and choose the Draw menu as before</p>

<ul>

<li>Adds TextGrid annotation to the waveform drawing</li>

</ul>

<p><img src="./assets/media/praat-drawn-soundtg.png" width="700"></p>

</div><div id="extracting-a-spectrogram" class="slide section level2">

<h1>Extracting a spectrogram</h1>

<p>“Paint” is for drawing spectrograms and other objects, but: we need the right <strong>object</strong> to do this</p>

<ul>

<li>Select Sound and click “View and Edit”</li>

<li>Select from the Spectrum menu “Extract visible spectrogram”</li>

</ul>

<p><img src="./assets/media/praat-extract-spec.png" width="700"></p>

</div><div id="painting-a-spectrogram" class="slide section level2">

<h1>Painting a spectrogram</h1>

<p>This sends a Spectrogram object to the object list; when we select this we get a “Paint” option under Draw</p>

<p><img src="./assets/media/praat-bbk-paint.png" width="400"> <img src="./assets/media/praat-paint-options.png" width="500"></p>

<p>The result: as expected, but a bit too tall for its width (make plot area wider/shorter)</p>

<p><img src="./assets/media/praat-painted.png" width="700"></p>

</div><div id="spectrograms-and-textgrids" class="slide section level2">

<h1>Spectrograms and TextGrids</h1>

<p>Drawing a spectrogram and a TextGrid at the same time is a bit more complicated</p>

<ol style="list-style-type: decimal">

<li>Paint the spectrogram, but <strong>uncheck “Garnish”</strong></li>

<li>Add the Y axis marks using the “Margins” menu</li>

</ol>

<p><img src="./assets/media/praat-marksleft.png" width="400"> <img src="./assets/media/praat-yaxis.png" width="400"></p>

<ol start="3" style="list-style-type: decimal">

<li>Add a Y axis label, usually “Frequency (Hz)”</li>

</ol>

<ul>

<li>I’ve also added a box around the plot here with “Margins” &gt; “Draw Inner Box”</li>

</ul>

<p><img src="./assets/media/praat-textleft.png" width="400"> <img src="./assets/media/praat-axistext.png" width="400"></p>

</div><div id="spectrograms-and-textgrids-1" class="slide section level2">

<h1>Spectrograms and TextGrids</h1>

<ol start="3" style="list-style-type: decimal">

<li><strong>Resize</strong> plot area to be taller than spectrogram (pictured), and Draw the TextGrid</li>

</ol>

<p><img src="./assets/media/praat-pretg.png" width="600"></p>

<p>The result: TextGrid annotations on top of the spectrogram</p>

<p><img src="./assets/media/praat-painted-tg.png" width="600"></p>

</div><div id="saving" class="slide section level2">

<h1>Saving</h1>

<p>As with everything else in Praat, you must <strong>save</strong> before closing the picture window or you will lose your work</p>

<ul>

<li>If you don’t keep the plot area in the same place (covering your figure or margins), you won’t save the entire figure</li>

</ul>

<p><img src="./assets/media/praat-save-picture.png" width="600"></p>

</div>

<div id="measuring-phonetic-properties" class="title-slide slide section level1"><h1>Measuring phonetic properties</h1></div><div id="why-numerical-measurements" class="slide section level2">

<h1>Why numerical measurements?</h1>

<p>Now we’ll turn to <strong>taking numerical measurements</strong> in Praat</p>

<ul>

<li>Actual calculation</li>

<li>Displaying <strong>figures</strong> of these measurements</li>

<li>Storing measurements as <strong>tabular data</strong> (at the end)</li>

</ul>

<p>More than showing an entire sound file as a waveform or spectrogram, focusing on a specific phonetic property can be useful</p>

<ul>

<li>Make a figure for this specific property</li>

<li>Focus on topic of interest for your discussion</li>

<li>Display with a TextGrid, a waveform, etc.</li>

</ul>

</div><div id="why-numerical-measurements-1" class="slide section level2">

<h1>Why numerical measurements?</h1>

<p>Also lets us measure many utterances and <strong>summarize</strong>, which also allows us to handle <strong>phonetic variation</strong></p>

<ul>

<li>Languages differ in their phonetic implementation of the “same” segments</li>

<li>Speakers of the same language produce it differently depending on their history, social stance, etc</li>

<li>Even phonologically identical words can differ slightly phonetically <span class="cite">Gahl (2008)</span></li>

</ul>

<p>Because of this it’s best to collect <strong>many observations</strong> and <strong>average</strong> or <strong>model</strong> the data to remove noise and variation</p>

<ul>

<li>Multiple speakers</li>

<li>Multiple repetitions</li>

<li>Multiple words</li>

</ul>

</div><div id="duration" class="slide section level2">

<h1>Duration</h1>

<p>One of the simplest measures: <strong>duration</strong> of segments or words</p>

<ul>

<li>Simply ending time of the interval minus its starting time (<span class="math inline"><em>t</em><sub>2</sub> − <em>t</em><sub>1</sub></span>), in seconds</li>

<li>Two ways to acquire this in Praat:

<ul>

<li>Displayed in viewing window when you select an interval</li>

<li>If you use the “Query” menu, a text box appears which you can copy-paste the value from</li>

</ul></li>

</ul>

<p><img src="./assets/media/praat-bbk-duration.png" width="700"></p>

</div><div id="model-use" class="slide section level2">

<h1>Model use</h1>

<p>An example from Babanki (<strong>bbk-prenas.wav</strong>): proportion of prenasalized consonants which is nasal <span class="cite">Faytak &amp; Akumbu (2021)</span></p>

<p><img src="./assets/media/praat-bbk-duration2.png" width="700"></p>

<ul>

<li>Not uncommon for continuants to stop up when prenasalized, e.g. /ⁿz/ &gt; [ndz]</li>

<li>But /ⁿz/ and /ⁿdz/ (etc.) are contrastive in Babanki</li>

<li>Babanki speakers produce <em>shorter, lighter prenasalization</em> before continuants</li>

<li>This may help to avoid merger of continuants and non-continuants</li>

</ul>

</div><div id="model-use-1" class="slide section level2">

<h1>Model use</h1>

<p>Other phenomena studied with duration (not exhaustive):</p>

<ul>

<li>Voice onset time <span class="cite">McKinney (1990); Connell (1994, 2002); Monaka (2006)</span></li>

<li>Compensatory lengthening <span class="cite">Hamann, Miatto, &amp; Downing (2019); Danis (2020)</span></li>

<li>Any other timing relation you can think of (many, many possibilities)

<ul>

<li>Consonant gemination</li>

<li>Long vowels</li>

<li>Lengthening of segments or syllables due to stress assignment</li>

</ul></li>

</ul>

</div><div id="pitch-fundamental-frequency-f0" class="slide section level2">

<h1>Pitch (fundamental frequency, f0)</h1>

<p>Pitch (and all other measurements we’ll talk about) have a dedicated <strong>menu</strong></p>

<ul>

<li>Turn on “show pitch” to use all other options</li>

<li><strong>f0 track</strong> appears over spectrogram (below) when “showing”</li>

</ul>

<p><img src="./assets/media/praat-pitch-menu.png" width="700"></p>

<p><img src="./assets/media/praat-bbk-pitch.png" width="700"></p>

</div><div id="pitch-settings" class="slide section level2">

<h1>Pitch settings</h1>

<p><strong>Settings</strong> for pitch are important</p>

<ul>

<li>If pitch range is not suited to the speaker, fake jumps in pitch can appear</li>

<li>Below, the low-falling tone has a fake jump, well above H for this speaker!</li>

<li>From our prior knowledge of the language we should <strong>overrule</strong> Praat</li>

</ul>

<p><img src="./assets/media/bbk-grass-beetle.png" width="700"></p>

</div><div id="pitch-settings-1" class="slide section level2">

<h1>Pitch settings</h1>

<p>A quick change to pitch range fixes the jump issue</p>

<ul>

<li>In “Settings…” under the Pitch menu</li>

<li>The pitch range was too high for the speaker, so we lower the pitch floor</li>

</ul>

<p><img src="./assets/media/praat-pitch-settings.png" width="700"></p>

<ul>

<li>This handles the low tones better</li>

</ul>

<p><img src="./assets/media/praat-bbk-fixed-pitch.png" width="700"></p>

<ul>

<li>If jumps don’t go away, the “Advanced pitch settings…” window offers some options</li>

</ul>

<p><img src="./assets/media/praat-advanced-pitch-settings.png" width="700"></p>

</div><div id="model-use-2" class="slide section level2">

<h1>Model use</h1>

<audio id="schwa" src="./assets/media/bbk-schwa.wav">

</audio>

<p>All tonal phenomena involve f0</p>

<ul>

<li>Lexical tone, downstep, downdrift, pitch reset, tone depression, lexical tone contrasts</li>

<li>Intonation (question formation, etc)</li>

</ul>

<p>Babanki example in <button onclick="document.getElementById('schwa').play()"> bbk-schwa.wav</button>:</p>

<ul>

<li>Prefixal L ( və̀-lɨ́m “males”) behave differently from stem L (bə̀lâŋ “plank”) when between two Hs

<ul>

<li>Third word is bə́lə̀ŋ “groundnut”</li>

</ul></li>

<li>HL(prefix)H raises to mid: HM(prefix)H <span class="cite">Akumbu (2019)</span></li>

</ul>

<p><img src="./assets/media/praat-bbk-mid.png" width="700"></p>

</div><div id="model-use-3" class="slide section level2">

<h1>Model use</h1>

<audio id="aboro" src="./assets/media/Part2_5_Rialland_Embosi_fig01.wav">

</audio>

<p>Sub-phonemic effects of intonation on tonemes can be examined <span class="cite">figure from Rialland &amp; Aborobongui (2016)</span></p>

<ul>

<li>Boundary tones (%) indicate sentence type</li>

<li>Effect of L% on lexical H in <button onclick="document.getElementById('aboro').play()"> the example below</button></li>

</ul>

<p><img src="./assets/media/rialland-aborobongui.png" width="700"></p>

<p>Other tone topics (not exhaustive):</p>

<ul>

<li>Tone depressor consonants <span class="cite">Traill, Khumalo, &amp; Fridjhon (1987); Chen &amp; Downing (2011); Mathes &amp; Chebanne (2018); Lotven &amp; Berkson (2019)</span></li>

<li>Formal representation of tone <span class="cite">Akumbu (2019); Gjersøe, Nformi, &amp; Paschen (2019); Myers, Namyalo, &amp; Kiriggwajjo (2019); McPherson (2020)</span></li>

<li>Downdrift, downstep, and pitch reset <span class="cite">Genzel &amp; Kügler (2011); Hamlaoui &amp; Makasso (2019); Oppong (2021)</span></li>

</ul>

</div><div id="intensity" class="slide section level2">

<h1>Intensity</h1>

<p>A measure of <strong>loudness</strong>, measured in decibels (dB)</p>

<ul>

<li>Intensity menu and settings are exactly parallel to Pitch menu and settings</li>

</ul>

<p><img src="./assets/media/praat-intensity-menu.png" width="700"></p>

<ul>

<li>The yellow intensity track can be hard to spot</li>

<li>Higher parts of track match darker parts of spectrogram and thicker parts of waveform</li>

</ul>

<p><img src="./assets/media/praat-bbk-intensity.png" width="700"></p>

</div><div id="model-use-4" class="slide section level2">

<h1>Model use</h1>

<p>Intensity is useful for measuring degree of constriction</p>

<ul>

<li>Degree of consonant constriction (or lenition)</li>

<li>Prosodic factors such as stress (in many languages)</li>

</ul>

<p>Babanki example: stressed (stems) and unstressed (prefixes) don’t seem to be differentiated by intensity</p>

<ul>

<li>But stem H has a longer duration</li>

</ul>

<p><img src="./assets/media/praat-bbk-intensity2.png" width="800"></p>

</div><div id="model-use-5" class="slide section level2">

<h1>Model use</h1>

<p>Implosive vs. non-implosive voiced stops have different intensity profiles <span class="cite">figure from Nagano-Madsen &amp; Thornell (2012)</span></p>

<ul>

<li>See also <span class="cite">Naidoo (2012)</span></li>

</ul>

<p><img src="./assets/media/nagano.png" width="600"></p>

<p>Numerous other uses in prosody</p>

</div><div id="f0-and-intensity-figures" class="slide section level2">

<h1>f0 and intensity figures</h1>

<p>f0 (pitch) and intensity tracks can easily be Drawn to figures as seen above</p>

<ul>

<li>In “Pitch” and “Intensity” menus, there is the option to Draw directly to the Picture window with or without a TextGrid</li>

<li>Best to combine with a TextGrid whenever possible</li>

<li>Below: pitch contour for Kejom <button onclick="document.getElementById('bush').play()"> [tə̀tāŋ tə́ tə́ꜜtóʔ]</button> “hills of bushes” <span class="cite">from Faytak &amp; Akumbu (2021)</span></li>

</ul>

<p><img src="./assets/media/praat-bbk-draw-pitch.png" width="700"></p>

</div><div id="formant-frequencies" class="slide section level2">

<h1>Formant frequencies</h1>

<p>Formant frequencies provide <strong>vowel quality</strong> and other contrasts</p>

<ul>

<li>Formant transitions show place of consonants</li>

<li>Lateral and nasal quality, etc.</li>

</ul>

<p><img src="./assets/media/praat-formant-menu.png" width="700"></p>

</div><div id="formant-frequencies-1" class="slide section level2">

<h1>Formant frequencies</h1>

<p>Turn on “show formants”, and formant tracks for the first three formants (F1, F2, F3) appear</p>

<ul>

<li>All have some inverse relationship with a property <span class="math inline"><em>x</em></span>: the higher the frequency, the less <span class="math inline"><em>x</em></span></li>

<li>F1 inversely relates to height (higher F1 = lower vowel)</li>

<li>F2 inversely relates to backness (higher F2 = fronter vowel)</li>

<li>F3 inversely relates to retroflexion (low F3 = more retroflexion) and other qualities</li>

</ul>

<p><img src="./assets/media/praat-bbk-formants.png" width="700"></p>

</div><div id="formant-settings" class="slide section level2">

<h1>Formant settings</h1>

<p>Estimating formant frequencies requires calibration for every individual speaker: low pitched voices need different settings compared to high pitched voices</p>

<ul>

<li>Often simplified to “men” versus “women”, but there is a lot of variation in pitch for each</li>

<li>Children (with very high f0) can be especially difficult</li>

</ul>

<p>The default settings work well for <strong>higher-pitched voices</strong></p>

<ul>

<li>Lower-pitched voices need <strong>fewer formants</strong> and a <strong>lower maximum frequency</strong></li>

</ul>

<p><img src="./assets/media/praat-formant-settings.png" width="700"></p>

</div><div id="formant-tracking" class="slide section level2">

<h1>Formant tracking</h1>

<p>The default settings of 5 formants in 5500 Hz (for higher-pitched voices) don’t work well for the very low-pitched voice of the Babanki speaker:</p>

<p><img src="./assets/media/praat-bbk-poor-track.png" width="700"></p>

<p>Better: changed to 4.5 formants, 4200 Hz; much lower frequency range</p>

<p><img src="./assets/media/praat-bbk-formants.png" width="700"></p>

</div><div id="formant-figures" class="slide section level2">

<h1>Formant figures</h1>

<p>Formant tracks work best in a plot of F1 against F2 (which is quite hard to make in Praat), but formant tracks can be drawn like any other measure</p>

<ul>

<li>Draw separately from TextGrid and “un-garnish”</li>

<li>Much like we did for the spectrogram + TextGrid combination</li>

<li>“Speckle” under “Draw” produces this from an extracted Formant object</li>

</ul>

<p><img src="./assets/media/praat-draw-speckle.png" width="700"></p>

</div><div id="f1-f2-scatterplots" class="slide section level2">

<h1>F1-F2 scatterplots</h1>

<p>F1-F2 scatterplots have F2 on the <span class="math inline"><em>x</em></span> axis, F1 on the <span class="math inline"><em>y</em></span> axis, with both axes <strong>reversed</strong></p>

<ul>

<li>Praat does have a <em>limited</em> ability to make scatterplots</li>

<li>Must manually specify plot size</li>

<li>Can only use these four point types: x + o .</li>

<li>Limited ability to label or make legends</li>

</ul>

<p><img src="./assets/media/praat-scatterplot.png" width="700"></p>

</div><div id="model-use-6" class="slide section level2">

<h1>Model use</h1>

<p>Better scatterplot figures can be made using tabular data (we’ll discuss later) <span class="cite">figure from Faytak &amp; Akumbu (2021)</span></p>

<ul>

<li>Here, ellipses indicate where each cloud of points is centered</li>

</ul>

<p><img src="./assets/media/faytak-akumbu-f1f2.png" width="500"></p>

<ul>

<li>With this plot it becomes clear why we reverse the axes: vowel space resembles the IPA vowel trapezoid</li>

</ul>

<p><img src="./assets/media/ipa-chart.png" width="500"></p>

</div><div id="model-use-7" class="slide section level2">

<h1>Model use</h1>

<p>Formant data is useful in figuring out <strong>harmony systems</strong>; ATR or otherwise</p>

<ul>

<li>Dagbani right-to-left ATR harmony also affects the low vowel /a/, counter to previous descriptions <span class="cite">figure from Hudu (2016)</span></li>

</ul>

<p><img src="./assets/media/hudu-2013.png" width="600"></p>

<ul>

<li>Moro’s height harmony system may condition ‘high’ and ‘low’ /ə/, previously thought to be transparent to harmony <span class="cite">Ritchart &amp; Rose (2015)</span></li>

<li>Note presentation of data in a <strong>table</strong> in addition to a scatterplot</li>

</ul>

<p><img src="./assets/media/ritchart1.png" width="600"></p>

<p><img src="./assets/media/ritchart2.png" width="600"></p>

<p>Other uses for formant measures (non-exhaustive):</p>

<ul>

<li>General description of vowel inventory <span class="cite">Koffi (2018), McPherson (2020)</span></li>

<li>Characterizing harmony systems <span class="cite">Starwalt (2008); McCollum &amp; Essegbey (2020)</span></li>

</ul>

</div><div id="voicing-pulses" class="slide section level2">

<h1>Voicing (“Pulses”)</h1>

<p>Praat also detects measures relating to <strong>voicing</strong>: these are grouped under the unintuitive name “Pulses”</p>

<ul>

<li>So called because voicing produces repeating, pulsing sounds</li>

<li>Detecting voicing = detecting regular pulses in the sound signal</li>

</ul>

<p>The Pulses menu contains the same “showing”, measure-getting, and drawing functions as other menus</p>

<p><img src="./assets/media/praat-pulse-menu.png" width="700"></p>

<p>The result: each detected “voice pulse”, shown over waveform</p>

<p><img src="./assets/media/praat-bbk-pulses.png" width="700"></p>

</div><div id="display-pulses" class="slide section level2">

<h1>Display pulses</h1>

<p>The pulses themselves can be plotted with a TextGrid like any other similar object</p>

<ul>

<li>Shaded areas indicate area where voice pulses occur repeatedly</li>

<li>Functions like a “voicing detector”</li>

</ul>

<p><img src="./assets/media/praat-drawn-pulses.png" width="700"></p>

</div><div id="voicing-report" class="slide section level2">

<h1>Voicing report</h1>

<p>If voicing has a predictable timing but varies in extent, the <strong>voicing report</strong> may be useful (access in the Pulses menu)</p>

<ul>

<li>Specifically the number after “Fraction of locally unvoiced frames”</li>

</ul>

<p><img src="./assets/media/praat-voice-report.png" width="700"></p>

</div><div id="model-use-8" class="slide section level2">

<h1>Model use</h1>

<p>Voicing in unexpected places is common for labial-velars; this can be confirmed by looking for pulses <span class="cite">figure from Connell (1994)</span></p>

<p><img src="./assets/media/connell-1994.png" width="600"></p>

<p>Other voicing-related topics:</p>

<ul>

<li>Mixed-voicing consonant clusters in Taa (“Khoi-san”) <span class="cite">Nakagawa (2008); Naumann (2016)</span></li>

<li>Lenition or devoicing of consonants <span class="cite">Solé, Hyman, &amp; Monaka (2010); Boyer &amp; Zsiga (2013); Bendjaballah &amp; Le Gac (2021)</span></li>

</ul>

</div>

<div id="text-output-and-tabular-data" class="title-slide slide section level1"><h1>Text output and tabular data</h1></div><div id="getting-out-of-praat" class="slide section level2">

<h1>Getting out of Praat</h1>

<p>Praat is useful, but it has important <strong>limitations</strong></p>

<ul>

<li>Hard to produce all types of figures</li>

<li>Can’t do statistical analysis (which is standard for phonetics)</li>

</ul>

<p>Because of this, we often need to <strong>export</strong> data from Praat into other programs</p>

</div><div id="tabular-data" class="slide section level2">

<h1>Tabular data</h1>

<p>The most effective way to export numerical measurements: <strong>tabular data</strong>, that is, <strong>spreadsheets</strong></p>

<ul>

<li>One observation (time point, segment, etc) per row</li>

<li>One measure per column</li>

<li>Name columns using the first row</li>

<li>Other columns give non-numerical information (speaker ID, segment, word, etc.)</li>

</ul>

<p>Excel or Google Drive work well (.xls, .txt, or .csv format):</p>

<p>sample tabular data</p>

</div><div id="spreadsheet-construction" class="slide section level2">

<h1>Spreadsheet construction</h1>

<p>Basic approach to making tabular data is to</p>

<ol style="list-style-type: decimal">

<li>Generate text output in Praat</li>

<li>Copy-paste into a spreadsheet</li>

<li>Add metadata</li>

</ol>

</div><div id="praat-text-output" class="slide section level2">

<h1>Praat text output</h1>

<p>Text output is generated using the <strong>menus</strong></p>

<ul>

<li>…</li>

</ul>

</div><div id="point-vs.-interval" class="slide section level2">

<h1>Point vs. interval</h1>

<p>Depending on what your <strong>cursor</strong> is doing, “Listing” will get two different kinds of text output</p>

<ul>

<li>If you have not selected an interval, you will get a <strong>point</strong> measurement</li>

<li>If you have selected an interval, you will get a <strong>list</strong></li>

</ul>

<p>A shortcut exists to get the <strong>midpoint</strong> of any interval</p>

<p><img src="./assets/media/praat-midpoint-select.png" width="700"></p>

</div><div id="get-versus-listing" class="slide section level2">

<h1>“Get…” versus “Listing…”</h1>

<p>“Get…” provides a measurement at a point, or a <strong>mean</strong> measurement across an interval</p>

<ul>

<li>“Get pitch”</li>

<li>“Get intensity”</li>

<li>“Get <span class="math inline"><em>n</em></span>th formant”</li>

</ul>

<p>“Listing…” provides <em>all</em> measures within an interval if selected</p>

<ul>

<li>“Pitch listing”</li>

<li>“Intensity listing”</li>

<li>“Formant listing”</li>

<li>(“Pulse listing”: timing of pulses)</li>

</ul>

<p>“Voice report” is an exception: needs an interval, and generates a large number of different measures</p>

</div><div id="exceptions" class="slide section level2">

<h1>Exceptions</h1>

<p>f0/pitch has some special options:</p>

<ul>

<li>“Get pitch” (mean f0 of interval, or instantaneous f0 at a point)</li>

<li>Minimum/maximum pitch (points)</li>

<li>Pitch listing (time series)</li>

</ul>

</div><div id="example-meanmaxmin-pitches" class="slide section level2">

<h1>Example: mean/max/min pitches</h1>

<p>Simple copy-paste, one observation per row</p>

<p>basic schematic image</p>

</div><div id="example-formant-listing" class="slide section level2">

<h1>Example: formant listing</h1>

<p>Listings are trickier:</p>

<ul>

<li>Comes with time points that need to be included</li>

<li>Number of time points varies</li>

<li></li>

</ul>

<p>Listing data is tricky, especially formant data, because it comes in multiple columns</p>

<ul>

<li>???</li>

</ul>

<p>Google Docs can split Praat formant text data into columns:</p>

<p><img src="./assets/media/gdocs-split-cols.png" width="700"></p>

<p>Excel can also handle this upon import (not pasting)</p>

<ul>

<li>This equally applies to pitch, intensity listings</li>

</ul>

</div><div id="listings-generally" class="slide section level2">

<h1>Listings generally</h1>

<p>If your data are in <strong>time series</strong> (multiple measures made in a row), like a formant or pitch track, you can try the following:</p>

<ol style="list-style-type: decimal">

<li>Paste in data as before</li>

<li>Count up and add number to a column (1, 2, 3, … <span class="math inline"><em>t</em><em>o</em><em>t</em><em>a</em><em>l</em></span>)</li>

<li>Write <span class="math inline"><em>t</em><em>o</em><em>t</em><em>a</em><em>l</em></span> in every row for that observation in another column</li>

</ol>

<p>simpler time series example (stack 2 obs.)</p>

</div><div id="coding" class="slide section level2">

<h1>Coding</h1>

<p>Beyond the scope of this tutorial, but more efficient in a number of areas: basic <strong>coding</strong></p>

<ul>

<li><strong>Praat scripting</strong> can quickly produce tabular data</li>

<li>Plots can be made using R (or Excel!)</li>

<li>Mostly <em>free</em> software</li>

</ul>

<p>While there is a learning curve, the improvement to the process may pay off</p>

</div>

<div id="break" class="title-slide slide section level1"><h1>BREAK</h1></div>

<div id="articulatory-data" class="title-slide slide section level1"><h1>Articulatory data</h1></div><div id="acoustics-vs.-articulation" class="slide section level2">

<h1>Acoustics vs. articulation</h1>

<p>Acoustics gives us an <strong>indirect idea</strong> of the movements of the articulators</p>

<p>Sometimes, though, we need to look directly at the articulators</p>

<ul>

<li>If there are multiple explanations for acoustics</li>

<li>If the examined sounds are totally unfamiliar or especially unusual</li>

<li>In the Bantoid area, this is not uncommon!</li>

</ul>

</div><div id="lip-articulation" class="slide section level2">

<h1>Lip articulation</h1>

<p>Movement of tongue and lips: lips are easily seen moving</p>

<ul>

<li>Mirror at 45 degree angle provides a side view</li>

</ul>

<p><img src="./assets/media/lip-mirror.png" width="600"></p>

<p>Babanki vowels:</p>

<ul>

<li>Spread, unrounded [i]</li>

<li>Compressed</li>

<li>Rounded [u]</li>

</ul>

<p><img src="./assets/media/bbk-lip.png" width="800"></p>

</div><div id="examples" class="slide section level2">

<h1>Examples</h1>

<p>Lip activity during Medumba [ʉ]: compressed like a bilabial stop, often leading to bilabial trill [ʙ] <span class="cite">Olson &amp; Meynadier (2015)</span></p>

<p><img src="./assets/media/kom-palatography.png" width="600"></p>

</div><div id="palatographs" class="slide section level2">

<h1>Palatographs</h1>

<p>More complex, but provide information on tongue-palate contact <span class="cite">Anderson (2008)</span></p>

<ul>

<li>stop and fricative place</li>

<li>certain aspects of vowel articulation</li>

</ul>

<p>Method</p>

<ul>

<li>paint tongue</li>

<li>one token involving one lingual consonant</li>

<li>open mouth, insert mirror, photograph</li>

</ul>

<p><img src="./assets/media/palatography-side.png" width="600"></p>

</div><div id="examples-1" class="slide section level2">

<h1>Examples</h1>

<p>Kom high vowels (which I will be talking about in my regular talk)</p>

<ul>

<li>Kom iz vs. i</li>

<li>Audio examples</li>

</ul>

<p><img src="./assets/media/kom-palatography.png" width="700"></p>

</div><div id="examples-2" class="slide section level2">

<h1>Examples</h1>

<p>Excellent evidence of the phonetic basis of a lingual contrast</p>

<ul>

<li>Dental vs. (post)alveolar stop contrast in Lusoga <span class="cite">Nabirye, de Schryver, &amp; Verhoeven (2016)</span></li>

</ul>

<p><img src="./assets/media/nabirye.png" width="700"></p>

</div><div id="equipment-2" class="slide section level2">

<h1>Equipment</h1>

<p>Everything that we’ve talked about involves <strong>minimal equipment</strong></p>

<ul>

<li>Smartphone camera or point-and-shoot camera</li>

<li><strong>Dental mirror</strong>: or hand-held metal mirror, about 6cm wide and 12cm long

<ul>

<li>Held outside for lip angles</li>

<li>Inserted against upper molars for palatography</li>

</ul></li>

<li>Edible pigment (chocolate powder, edible charcoal) for palatography</li>

<li>A brush for painting the tongue (I prefer a narrow paintbrush or a makeup brush)</li>

</ul>

<p>Optional:</p>

<ul>

<li>Phone tripod or camera tripod</li>

<li>Photography lighting</li>

</ul>

</div><div id="figures-vs.-tabular-data" class="slide section level2">

<h1>Figures vs. tabular data</h1>

<p>The value of photographic evidence as a figure should be obvious</p>

<p>In exceptional cases, you may measure some physical attribute of articulatory pictures/images and convert that to <strong>tabular data</strong></p>

<ul>

<li>i.e. ratio of lip opening to lip width (or height-height) in pixels</li>

<li>lip example/schematic</li>

</ul>

</div><div id="other-articulations" class="slide section level2">

<h1>Other articulations</h1>

<p>It should be mentioned that certain articulations further back are not discussed here</p>

<ul>

<li>Dorsal or pharyngeal consonants</li>

<li>Complex tongue shapes, as in clicks</li>

<li>Advanced/retracted tongue root</li>

</ul>

<p>However, <strong>ultrasound</strong> technology is gradually making it easier to image these articulations <span class="cite">Miller, Namaseb &amp; Iskarous (2007); Hudu (2014)</span></p>

<ul>

<li>Entirely portable and non-invasive</li>

<li>But some significant technical barriers remain</li>

</ul>

</div>

<div id="practical-considerations" class="title-slide slide section level1"><h1>Practical considerations</h1></div><div id="file-naming-and-metadata" class="slide section level2">

<h1>File naming and metadata</h1>

<p>Name your recording files according to the same logical pattern</p>

<ul>

<li>Date, language, topic</li>

<li>Avoid duplicating names</li>

<li>Avoid vague names</li>

</ul>

<p>To identify further details, speak them during <em>the recording itself</em></p>

<ul>

<li>Identify and name yourself</li>

<li>Identify speaker(s) and their roles if this is not sensitive information</li>

<li>Identify anyone else who may be heard in the recording (assistants, translators, etc.)</li>

<li>Give time, date, and location of recording</li>

</ul>

</div><div id="file-backups" class="slide section level2">

<h1>File backups</h1>

<p>Back up <em>every recording</em> in multiple locations if possible, to avoid technological problems or theft destroying your work</p>

<ul>

<li>SD cards or thumb drives</li>

<li>Multiple computers (share key files with a trusted colleague)</li>

<li>Email small files to yourself (download as attachments later)</li>

<li>Long-term cloud storage (Google Drive, OneDrive, Box, Dropbox, etc) is ideal but uploading may be expensive</li>

</ul>

</div><div id="tabular-data-1" class="slide section level2">

<h1>Tabular data</h1>

<p>Tabular data consisting of many measures needs to be averaged, summarized (mean/standard deviation), or submitted to a statistical model</p>

<p>Averaging and basic statistical models can be done on this data, using Excel’s Data Analysis Tools (need to install)</p>

<ul>

<li>While Excel <em>works</em>, learning a dedicated statistical program is better in the long run</li>

</ul>

<p>picture example?</p>

</div><div id="statistics" class="slide section level2">

<h1>Statistics</h1>

<p>Simple statistical analysis and modeling are standard in phonetics for analysis of numerical data (t-testing, linear models, curve fitting, etc)</p>

<ul>

<li>We acknowledge this is not practical for all attendees, but collaborators can help guide this work</li>

<li>Having nicely formatted tabular data is crucial to this handoff</li>

</ul>

<p>If you want to try stats yourself, it’s best to find software for handling tabular data:</p>

<ul>

<li><a href="https://www.r-project.org/">R</a> is free software which is useful for statistical analysis</li>

<li>Excel can also be used</li>

<li>Simple plots can also be made in Excel and R</li>

</ul>

</div><div id="statistical-power" class="slide section level2">

<h1>Statistical power</h1>

<p>Because of the need to model the data, it’s important to have enough <strong>statistical power</strong></p>

<ul>

<li>Need to ensure you have collected numerous repetitions of the phenomenon you’re after</li>

<li>Need to ensure that enough <strong>speakers</strong> are recorded (the more the better)

<ul>

<li>To get at the community average, instead of the idiosyncrasies of one speaker</li>

</ul></li>

</ul>

</div>

<div id="conclusions" class="title-slide slide section level1"><h1>Conclusions</h1></div><div id="summary" class="slide section level2">

<h1>Summary</h1>

<p>We’ve covered:</p>

<ul>

<li>Basics of instrumental phonetics</li>

<li>Praat (annotations, figures, measurements)</li>

<li>Text and tabular data</li>

<li>Photography for articulation data</li>

<li>Practical tips</li>

</ul>

<p>What remains to be seen:</p>

<ul>

<li>Long-term prospects for the methods</li>

<li>Unanticipated stumbling blocks</li>

<li>Incorporating further methodological advances</li>

</ul>

</div><div id="an-audit" class="slide section level2">

<h1>An audit</h1>

<p>In compiling these slides and the references they contain, I reflected upon:</p>

<ul>

<li>The current state of the phonetics literature for African languages</li>

<li>Who writes that literature</li>

<li>Who is cited here</li>

</ul>

<p>It is clear that African linguists are under-represented at every level, regardless of how you define “African linguist”</p>

<p>figure showing count of first/any authors of African extraction/birth</p>

<p>figure showing count of first/any authors of African <em>affiliation</em></p>

</div><div id="open-discussion" class="slide section level2">

<h1>Open discussion</h1>

<p>Some potential topics for discussion:</p>

<ul>

<li>How can we build capacity for this work in Africa’s universities?</li>

<li>Can existing high-quality documentary work be used as a starting point?</li>

<li>How can we advise this work when (not “if”) students decide to pursue it?</li>

<li>What should be the role of linguists off the continent in developing this area?</li>

</ul>

</div><div id="references-1" class="slide section level2 bib">

<h1>References</h1>

<p>Akumbu, P. (2019). A featural analysis of mid and downstepped high tone in Babanki. In Clem, E., Jenks, P., &amp; Sande, H., eds., <em>Theory and description in African linguistics: Selected papers from the 47th Annual Conference on African Linguistics</em>, 3–20. <a href="https://langsci-press.org/catalog/view/192/1150/1590-1">PDF</a></p>

<p>Anderson, V. (2008). Static palatography for language fieldwork. <em>Language Documentation &amp; Conservation</em>, 2(1), 1-27. <a href="https://scholarspace.manoa.hawaii.edu/handle/10125/1808">Article</a></p>

<p>Bendjaballah, S. &amp; Le Gac, D. (2021). The acoustics of word-initial and word-internal voiced stops in Somali. <em>Journal of the International Phonetic Association</em>, first view. <a href="https://doi.org/10.1017/S0025100321000281">Abstract</a></p>

<p>Boyer, O., &amp; Zsiga, E. (2013). Phonological devoicing and phonetic voicing in Setswana. In Ọla Orie, Ọ. and Sanders, K., eds., <em>Selected Proceedings of the Annual Conference on African Linguistics</em>, 43, 82-89. <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.657.5153&rep=rep1&type=pdf">PDF</a></p>

<p>Connell, B. (1994). The structure of labial-velar stops. <em>Journal of Phonetics</em>, 22(4), 441-476. <a href="https://doi.org/10.1016/S0095-4470(19)30295-5">Abstract</a></p>

<p>Danis, N. (2020). Yorùbá vowel deletion involves compensatory lengthening: Evidence from phonetics. <em>Stellenbosch Papers in Linguistics Plus</em>, 60(1), 1-12. <a href="https://hdl.handle.net/10520/ejc-spilplus-v60-n1-a1">Abstract &amp; PDF</a></p>

<p>Faytak, M., &amp; Akumbu, P. W. (2021). Kejom (Babanki). <em>Journal of the International Phonetic Association</em>, 51(2), 333-354. <a href="https://doi.org/10.1017/S0025100319000264">Article</a></p>

<p>Gahl, S. (2008). <em>Time</em> and <em>Thyme</em> Are not Homophones: The Effect of Lemma Frequency on Word Durations in Spontaneous Speech. <em>Language</em> 84(3), 474-496. <a href="https://doi.org/10.1353/lan.0.0035">Article</a></p>

<p>Ge, C., Xiong, Y., &amp; Mok, P. (2021). How reliable are phonetic data collected remotely? Comparison of recording devices and environments on acoustic measurements. In <em>Proc Interspeech 2021</em>, 1683-1687. <a href="http://ling.cuhk.edu.hk/people/peggy/GeXiongMok_Interspeech2021.pdf">PDF</a></p>

<p>Genzel, S. &amp; Kügler, F. (2011). Phonetic realization of automatic (downdrift) and non-automatic downstep in Akan. <em>Proceedings of ICPhS 17</em>, Hong Kong. <a href="http://icphs2011.hk.lt.cityu.edu.hk/resources/OnlineProceedings/RegularSession/Genzel/Genzel.pdf">PDF</a></p>

<p>Gjersøe, S., Nformi, J., &amp; Paschen, L. (2019). Hybrid falling tones in Limbum. In Clem, E., Jenks, P. &amp; Sande, H., eds., <em>Theory and Description in African Linguistics: Selected Papers from the 47th Annual Conference on African Linguistics</em>, 95-118. <a href="https://langsci-press.org/catalog/view/192/1484/1595-1">PDF</a></p>

<p>Hamlaoui, F. &amp; Makasso, E. (2019). Downstep and recursive phonological phrases in Bàsàá (Bantu A43). In Clem, E., Jenks, P. &amp; Sande, H., eds., <em>Theory and Description in African Linguistics: Selected Papers from the 47th Annual Conference on African Linguistics</em>, 155-175. <a href="https://langsci-press.org/catalog/view/192/1487/1598-1">PDF</a>.</p>

<p>Hudu, F. (2014). [ATR] feature involves a distinct tongue root articulation: Evidence from ultrasound imaging. <em>Lingua</em>, 143, 36-51. <a href="https://doi.org/10.1016/j.lingua.2013.12.009">Abstract</a></p>

<p>Hudu, F. (2016). A phonetic inquiry into Dagbani vowel neutralisations. <em>Journal of African Languages and Linguistics</em>, (37)1, 59-89. <a href="https://doi.org/10.1515/jall-2016-0002">Abstract</a></p>

<p>Hyman, L. (2014). How to study a tone language. <em>Language Documentation &amp; Conservation</em>, 8, 525-562. <a href="https://scholarspace.manoa.hawaii.edu/handle/10125/24624">Article</a></p>

<p>Koffi, E. (2018). The acoustic vowel space of Anyi in light of the cardinal vowel system and the Dispersion Focalization Theory. In Kandybowicz, J., Major, T., Torrence, H., &amp; Duncan, P., eds., <em>African linguistics on the prairie: Selected papers from the 45th Annual Conference on African Linguistics</em>. <a href="https://langsci-press.org/catalog/view/120/1321/1099-2">PDF</a></p>

<p>Ladefoged, P. (1968). <em>A phonetic study of West African languages: An auditory-instrumental survey.</em> Cambridge University Press.</p>

<p>Lotven, S. &amp; Berkson, K. (2019). The phonetics and phonology of depressor consonants in Gengbe. In Clem, E., Jenks, P. &amp; Sande, H., eds., <em>Theory and Description in African Linguistics: Selected Papers from the 47th Annual Conference on African Linguistics</em>, 249-268. <a href="https://langsci-press.org/catalog/view/192/1492/1603-1">PDF</a></p>

<p>Maddieson, I. &amp; Sands, B. (2019). The sounds of the Bantu languages. In Van de Velde, M., Bostoen, K., Nurse, D., &amp; Philippson, G., eds., <em>The Bantu Languages: Second Edition</em>, 79-127. Routledge. <a href="https://www.researchgate.net/profile/Bonny-Sands/publication/323369007_The_sounds_of_the_Bantu_languages/links/5a906c28aca2721405622bfb/The-sounds-of-the-Bantu-languages.pdf">Preprint</a></p>

<p>Mathes, T. &amp; Chebanne, A. (2018). High tone lowering and raising in Tsua. <em>Stellenbosch Papers in Linguistics Plus</em>, 54, 1-16. <a href="https://www.ajol.info/index.php/splp/article/view/184478">Abstract &amp; PDF</a></p>

<p>McCollum, A. &amp; Essegbey, J. (2020). Initial prominence and progressive vowel harmony in Tutrugbu <em>Phonological Data and Analysis</em> 2(3), 1-37. <a href="https://doi.org/10.3765/pda.v2art3.14">Abstract &amp; PDF</a></p>

<p>McKinney, N. (1990). Temporal characteristics of fortis stops and affricates in Tyap and Jju. <em>Journal of Phonetics</em>, <a href="https://doi.org/10.1016/S0095-4470(19)30392-4">Abstract</a></p>

<p>McPherson, L. (2020). Seenku. <em>Journal of the International Phonetic Association</em>, 50(2), 220-239. <a href="https://doi.org/10.1017/S0025100318000312">Abstract</a></p>

<p>Miller, A., Namaseb, L., &amp; Iskarous, K. (2007). Tongue body constriction differences in click types. <em>Laboratory Phonology</em>, 9, 643-656. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.135.2851&rep=rep1&type=pdf">PDF</a></p>

<p>Monaka, K. (2005). Shekgalagari stops and theories of phonological representation. <em>Lwati: A Journal of Contemporary Research</em>, 2, 24-42. <a href="https://doi.org/10.4314/lwati.v2i1.36780">Abstract &amp; PDF</a></p>

<p>Myers, S., Namyalo, S., &amp; Kiriggwajjo, A. (2019). F0 timing and tone contrasts in Luganda. Phonetica, 76(1), 55-81. <a href="https://doi.org/10.1159/000491073">Abstract</a></p>

<p>Nabirye, M., de Schryver, G., &amp; Verhoeven, J. (2016). Lusoga (Lutenga). <em>Journal of the International Phonetic Association</em>, 46(2), 219-228. <a href="https://doi:10.1017/S0025100315000249">Abstract &amp; PDF</a></p>

<p>Nagano-Madsen, Y. &amp; Thornell, C. (2012). Acoustic properties of implosives in Bantu Mpiemo. In Eriksson, A. &amp; Abelin, Å., eds., <em>Proceedings of FONETIK 2012</em>, Gothenburg, 73-76. <a href="

http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.397.802&rep=rep1&type=pdf#page=81">PDF</a></p>

<p>Naidoo, S. (2012). A re-evaluation of the Zulu implosive [ɓ]. <em>South African Journal of African Languages</em>, 30(1), 1-10. <a href="https://doi.org/10.1080/02572117.2010.10587331">Abstract</a></p>

<p>Nakagawa, H. (2008). Aspects of the phonetic and phonological structure of the G|ui language (Doctoral dissertation). <a href="https://core.ac.uk/download/pdf/39664836.pdf">Synopsis</a></p>

<p>Naumann, C. (2016). The phoneme inventory of Taa (West !Xoon dialect). In Vossen, R. &amp; Haacke, W., eds., <em>Lone Tree: Scholarship in Service of the Koon. Essays in memory of Anthony Traill</em>. Köln: Rüdiger Köppe Velag. <a href="https://d1wqtxts1xzle7.cloudfront.net/54707358/Naumann2009PhonemeInventoryTaaMS-with-cover-page-v2.pdf?Expires=1647648067&Signature=Q8aXSTuE9W419Bls~PVVILRHSZ~Ownk82e~1DvLJlVD2Zzp40MBMBjVUJk3Z9Hv00yAAoopFy8LIC0hG~mn2ChPBeJ2EQKtpjK90wvNwyl7AzU2uK1oYhJgNO0BQsH~ZpsW-eibvYlODvm7ADrIRJf~Q9iUopqkmPMFSTV2Ri4DBhxJ9qoSB3LGMkrS3dGRP42biILfDxSqU2H71Yy4Q~~rICVWZaNyKWFBnCc0gEWIbPT3SdY9PqbzB0iCWa8fO-00BGjlw7k0hekGi7Q7swUbYpw0F9USh-DmNkKFRE5Bfz~7Uuw73tFacKra1DR~BsSGJbNgFzXCiktPvJUCa-Q__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">PDF</a></p>

<p>Olson, K. &amp; Meynadier, Y. (2015) On Medumba bilabial trills and vowels. <em>Proceedings of ICPhS 18</em>, Glasgow. <a href="https://hal.archives-ouvertes.fr/hal-01211220/file/2015_ICPhS_Olson.pdf">PDF</a></p>

<p>Oppong, O. (2021). Pitch reset in Asante Twi, a dialect of Akan. MA Thesis, University of Helsinki. <a href="http://hdl.handle.net/10138/331097">Abstract &amp; PDF</a></p>

<p>Parker, S. (2008). Sound level protrusions as physical correlates of sonority. <em>Journal of Phonetics</em>, 36(1), 55-90. <a href="https://doi.org/10.1016/j.wocn.2007.09.003">Abstract</a></p>

<p>Rialland, A. &amp; Aborobongui, M. (2016). How intonations interact with tones in Embosi (Bantu C25), a two-tone language without downdrift. In Downing, L. &amp; Rialland, A., eds., <em>Intonation in African tone languages</em> 195-xxx. Berlin: Mouton de Gruyter. <a href="https://doi.org/10.1515/9783110503524-007">DOI</a> <a href="

https://direct.mit.edu/coli/article/46/4/713/97329/Sparse-Transcription">PDF</a></p>

<p>Ritchart, A. &amp; Rose, S. (2015). Schwas in Moro Vowel Harmony. In Kramer, R., Zsiga, E., &amp; Tlale Boyer, O., eds., <em>Selected Proceedings of the 44th Annual Conference on African Linguistics</em>, 231-242. <a href="https://pages.ucsd.edu/~aritchart/Ritchart_Rose_2015_ACAL44.pdf">PDF</a></p>

<p>Sanker, C., Babinski, S., Burns, R., Evans, M., Johns, J., Kim, J., Smith, S., Weber, N., &amp; Bowern, C. (2021). (Don’t) try this at home! The effects of recording devices and software on phonetic analysis. <em>Language</em>, 97(4), e360-e382. <a href="https://muse.jhu.edu/article/840967/pdf">PDF</a></p>

<p>Solé, M. J., Hyman, L. M., &amp; Monaka, K. C. (2010). More on post-nasal devoicing: The case of Shekgalagari. <em>Journal of Phonetics</em>, 38(4), 604-615. <a href="https://doi.org/10.1016/j.wocn.2010.09.002">Abstract</a> <a href="http://www.linguistics.berkeley.edu/PhonLab/documents/2009/Shekgalagari_USletter_PLAR.pdf">Preprint</a></p>

<p>Starwalt, C. (2008). The acoustic correlates of ATR harmony in seven-and nine-vowel African languages: A phonetic inquiry into phonological structure. PhD dissertation, The University of Texas at Arlington. <a href="https://www.proquest.com/docview/304842357?pq-origsite=gscholar&fromopenview=true">PDF</a></p>

<p>Traill, A., Khumalo, J., &amp; Fridjhon, P. (1987). Depressing facts about Zulu. <em>African Studies</em> 46(2), 255-274. <a href="https://doi.org/10.1080/00020188708707678">Abstract &amp; PDF</a></p>

<p>Whalen, D. H., DiCanio, C., &amp; Dockum, R. (2020). Phonetic documentation in three collections: Topics and evolution. <em>Journal of the International Phonetic Association</em>, ##, 1-27. <a href="https://doi.org/10.1017/S0025100320000079">Abstract</a></p>

<p>Zee, E. (1981). Effect of vowel quality on perception of post–vocalic nasal consonants in noise. <em>Journal of Phonetics</em>, 9(1), 35-48. <a href="https://doi.org/10.1016/S0095-4470(19)30925-8">Abstract</a></p>

</div>

</body>

</html>
