<?xml version="1.0" encoding="utf-8"?>

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"

 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/solid.css" integrity="sha384-VGP9aw4WtGH/uPAOseYxZ+Vz/vaTb1ehm1bwx92Fm8dTrE+3boLfF1SpAtB1z7HW" crossorigin="anonymous">

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/fontawesome.css" integrity="sha384-1rquJLNOM3ijoueaaeS5m+McXPJCGdr5HcA03/VHXxcp2kX2sUrQDmFc3jR5i/C7" crossorigin="anonymous">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

  <meta http-equiv="Content-Style-Type" content="text/css" />

  <meta name="generator" content="pandoc" />

  <meta name="author" content="Banto1d, 23 March 2022" />

  <title>[verb]ing phonetics: workshop 1</title>

  <style type="text/css">

    code{white-space: pre-wrap;}

    span.smallcaps{font-variant: small-caps;}

    span.underline{text-decoration: underline;}

    div.column{display: inline-block; vertical-align: top; width: 50%;}

    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}

    ul.task-list{list-style: none;}

    .display.math{display: block; text-align: center; margin: 0.5rem auto;}

  </style>

  <link rel="stylesheet" type="text/css" media="screen, projection, print"

    href="assets/styles/slidy.css" />

  <script src="assets/scripts/slidy.js"

    charset="utf-8" type="text/javascript"></script>

</head>

<body>

<div class="slide titlepage">

  <h1 class="title">[verb]ing phonetics: workshop 1</h1>

  <p class="author">

Banto1d, 23 March 2022

  </p>

  <p class="date">Universität Hamburg<br/> Matthew Faytak<br/> Katie Franich</p>

</div>

<div id="overview" class="slide section level2">

<h1>Overview</h1>

<p>Part 1:</p>

<ul>

<li>Assumptions</li>

<li>Why (instrumental) phonetics?</li>

<li>Acoustic data

<ul>

<li>Using Praat</li>

<li>Types of measurements</li>

</ul></li>

</ul>

<p>Part 2:</p>

<ul>

<li>Articulatory data</li>

<li>Data management</li>

<li>Using the data</li>

<li>Open discussion period</li>

</ul>

</div>

<div id="about-the-slides" class="slide section level2">

<h1>About the slides</h1>

<p>These slides are a <strong>web page</strong></p>

<ul>

<li>Use right, left arrow keys to navigate (or click to advance)</li>

<li>Press “A” to see all slides at once, and “A” again to go back to slide view</li>

<li>Links are formatted like <a href="https://www.youtube.com/watch?v=eVaUDAqrpKk">this</a></li>

<li>References look like <span class="cite">This (1985)</span></li>

<li>All references have links provided in the bibliography</li>

</ul>

<p>The slides are hosted <a href="https://github.com/mfaytak/afriphon">here</a> on GitHub</p>

<ul>

<li>Along with all associated media</li>

<li>This slideshow’s URL is <a href="https://mfaytak.github.io/afriphon/btd-1.html">mfaytak.github.io/afriphon/btd-1.html</a></li>

</ul>

</div>

<div id="some-assumptions" class="title-slide slide section level1">

<h1>Some assumptions</h1>



</div>

<div id="participants" class="slide section level2">

<h1>Participants</h1>

<p>We presume that you are:</p>

<ul>

<li>Employed by, or trained at, a university on the African continent (sub-Sahara)</li>

<li>Researching in a low-resource context

<ul>

<li>External grants are uncommon</li>

<li>Institutional support is low</li>

</ul></li>

<li>Familiar with phonetics in theory, but not necessarily in practice</li>

</ul>

<p>If you are not in this group, we ask that you <strong>prioritize</strong> those in this group for questions and feedback</p>

</div>

<div id="all-of-us" class="slide section level2">

<h1>All of us</h1>

<p>Let’s assume that we are all committed to:</p>

<ul>

<li>Improving empirical <strong>coverage</strong> of African languages’ sound structures</li>

<li>Building speech data <strong>resources</strong> for African languages

<ul>

<li>Ethos: “some data is better than no data”</li>

<li>Important as starting point for technical development</li>

</ul></li>

<li>Developing <strong>capacity</strong> for an African phonetics practice</li>

<li>Doing these in a way which is adapted to local needs and demands</li>

</ul>

</div>



<div id="why-phonetics" class="title-slide slide section level1">

<h1>Why phonetics?</h1>



</div>

<div id="definitions" class="slide section level2">

<h1>Definitions</h1>

<p>This workshop is an introduction to <strong>instrumental</strong> phonetics</p>

<ul>

<li>Relying on instrumental readouts for analysis</li>

<li>Not exclusively <strong>impressionistic</strong>: using the ear and transcribing speech sounds</li>

</ul>

<p>“Phonetic” work may also refer to non-contrastive <strong>subphonemic detail</strong></p>

<ul>

<li><em>The specific way</em> a phonemic contrast is produced</li>

<li>This is also important here, but we are focusing on instrumental methods</li>

</ul>

</div>

<div id="why-instrumental-phonetics" class="slide section level2">

<h1>Why instrumental phonetics?</h1>

<p>Several practical advantages over impressionistic approaches</p>

<ul>

<li><strong>Neutrality</strong> in the face of analytical and perceptual bias</li>

<li><strong>Precision</strong> and reliability in detecting contrasts</li>

<li><strong>Community use</strong> of the created data</li>

</ul>

</div>

<div id="neutrality" class="slide section level2">

<h1>Neutrality</h1>

<p>In impressionistic phonological description, all presentation of data is filtered through the worker’s theoretical analysis</p>

<ul>

<li>For example: autosegmental representations often make transcriptions more abstract <span class="cite">Hyman (2014):545</span></li>

</ul>

<p><img src="./assets/media/hyman-theory.png" width="700"></p>

<p>Phonetic recordings allow better testing of hypotheses about phonological structure</p>

<ul>

<li>Recordings do not intrinsically involve an analysis, and can be reanalyzed at a later date</li>

<li>Transcribed data (being analyzed) is much harder to use for this purpose</li>

</ul>

</div>

<div id="neutrality-1" class="slide section level2">

<h1>Neutrality</h1>

<p>Even a trained phonetic ear is prone to making occasional mistakes based on <strong>perceptual bias</strong></p>

<ul>

<li>For example: nasal consonant codas are more often misidentified after non-low vowels <span class="cite">Zee (1981)</span></li>

</ul>

<p><img src="./assets/media/zee.png" width="600"></p>

<ul>

<li>Transcription mistakes permanently enter the record</li>

</ul>

</div>

<div id="precision" class="slide section level2">

<h1>Precision</h1>

<p>Not all contrasts can be easily described by the analyst’s ear, especially in the moment</p>

<ul>

<li>Fine vowel contrasts (especially central vowels)</li>

<li>Diphthongs versus consonant secondary articulation</li>

<li>Prenasalization versus N+C clusters</li>

<li>Subtle differences in tone level and contour</li>

<li>Multiple downsteps/upsteps</li>

</ul>

<p>Recordings allow for careful listening later</p>

</div>

<div id="community-use" class="slide section level2">

<h1>Community use</h1>

<p>Recordings are required for instrumental phonetic work: many incidental benefits</p>

<ul>

<li>Speaker community may access the data

<ul>

<li>Literacy development (teaching tools)</li>

<li>Technical development (speech resources)</li>

</ul></li>

<li>Community of scientific researchers may access the data

<ul>

<li>New analyses</li>

<li>Comparative work</li>

</ul></li>

<li>Analysis may be replicated</li>

</ul>

</div>

<div id="complementary-methods" class="slide section level2">

<h1>Complementary methods</h1>

<p>The aim is not to <em>displace</em> impression-based methods, but to <em>complement</em> them</p>

<ul>

<li>Transcription will always be needed at some level</li>

<li>Our point is that it should not be <em>exclusively</em> relied on as the analytical object</li>

<li>Whenever possible, transcriptions ought to be supplemented with recordings, visualizations of recordings, or instrumental measures as evidence</li>

<li>Instrumental measures as “second opinion” for analysis</li>

</ul>

</div>



<div id="recording-acoustic-data" class="title-slide slide section level1">

<h1>Recording acoustic data</h1>



</div>

<div id="desired-qualities" class="slide section level2">

<h1>Desired qualities</h1>

<p>We always want acoustic speech data to be:</p>

<ul>

<li>Low in background <strong>noise</strong></li>

<li>Sufficiently <strong>loud</strong> against background noise, but not too loud</li>

<li>Free of <strong>echo</strong></li>

</ul>

<p>Certain details of format are also important:</p>

<ul>

<li>Record using a high <strong>sampling rate</strong>, at least 22.1 kHz</li>

<li>Save in <strong>non-compressed</strong> format (such as <strong>.WAV</strong>; avoid .MP3)</li>

</ul>

</div>

<div id="good-recording" class="slide section level2">

<h1>Good recording</h1>

<audio id="good" src="./assets/media/best-quality.wav">

</audio>

<p>Here is an example of a good recording</p>

<ul>

<li><button onclick="document.getElementById(&#39;good&#39;).play()">

“La plume de ma tante”

</button></li>

<li>Speaker’s voice is much louder than background, but is not <em>too</em> loud</li>

<li>Background is free of avoidable noise</li>

<li>Practically no echo</li>

</ul>

<p>The following slides contain recordings which fail on one of the points above</p>

</div>

<div id="too-noisy" class="slide section level2">

<h1>Too noisy</h1>

<p>Recordings should not contain excessive background noise</p>

<audio id="noise2" src="./assets/media/noisy2.wav">

</audio>

<audio id="scuff" src="./assets/media/scuffing.wav">

</audio>

<ul>

<li><button onclick="document.getElementById(&#39;noise2&#39;).play()">

Continuous noise

</button>

from a fan</li>

<li><button onclick="document.getElementById(&#39;scuff&#39;).play()">

Intermittent noise

</button>

from touching the microphone</li>

</ul>

<p>Any noise, however quiet to your ears in the moment, will be much louder in the recording later</p>

</div>

<div id="how-to-improve" class="slide section level2">

<h1>How to improve</h1>

<p>Listen carefully to your surroundings, and avoid:</p>

<ul>

<li>Rain on the roof (especially metal roofs)</li>

<li>Appliances (refrigerators, any motors or fans)</li>

<li>Busy roads (trucks, taxis)</li>

<li>Chickens, goats, children, etc.</li>

</ul>

<p>Speaker should also minimize non-speech noise:</p>

<ul>

<li>Touching or scratching microphone, or contacting shirt collar</li>

<li>Producing background noises when emphatic (striking chest or table, clapping hands)</li>

<li>Phone ringing or vibrating</li>

</ul>

</div>

<div id="too-much-echo" class="slide section level2">

<h1>Too much echo</h1>

<audio id="echo1" src="./assets/media/echo1.wav">

</audio>

<audio id="echo2" src="./assets/media/echo2.wav">

</audio>

<p>If echo is strong, speech ends up overlapping itself; problem for listening and analysis later</p>

<ul>

<li><button onclick="document.getElementById(&#39;echo1&#39;).play()">

Slight echo

</button>

(in tiled hallway)</li>

<li><button onclick="document.getElementById(&#39;echo2&#39;).play()">

More echo

</button>

(in concrete stairwell)</li>

</ul>

<p>How to improve: listen for echo and choose surroundings which have less</p>

<ul>

<li>“Soft” rooms reduce echo (couches, carpets, pillows, hanging clothes); tile, stone, and cement produce echo</li>

<li>Record in the back seat of a car (motor off) if available</li>

<li>Record outside if no suitable room exists</li>

</ul>

</div>

<div id="too-loud-clipped" class="slide section level2">

<h1>Too loud (clipped)</h1>

<audio id="clip" src="./assets/media/clipping.wav">

</audio>

<audio id="pop" src="./assets/media/popping.wav">

</audio>

<p>If the speaker is too loud and/or too close to the microphone, the device cannot respond enough; <strong>clipping</strong> results</p>

<ul>

<li><button onclick="document.getElementById(&#39;clip&#39;).play()">

Clipping of whole utterance

</button></li>

<li>This can also happen for <button onclick="document.getElementById('pop').play()"> stops and fricatives only</button>, where the releases “pop” in the microphone</li>

</ul>

<p>How to improve: make test recordings after you position your microphones</p>

<ul>

<li>If there is general clipping, microphone needs to be further away or speaker needs to be quieter</li>

<li>If stops “pop”, position microphone to the side of the mouth</li>

<li><strong>Gain</strong> can often be adjusted if you are using a recorder</li>

</ul>

</div>

<div id="equipment" class="slide section level2">

<h1>Equipment</h1>

<p>Not much equipment required: something to make recordings on</p>

<ul>

<li>Laptop computer</li>

<li>Smartphone with recording app

<ul>

<li>“Awesome Voice Recorder X” (free with ads) is a good app</li>

<li>Others must definitely exist</li>

</ul></li>

<li>Hand recorder/memo recorder</li>

<li>Professional recorder (Zoom H4N, etc)</li>

</ul>

<p>A way of transferring files off of the device and storing for future analysis:</p>

<ul>

<li>SD card</li>

<li>USB drive or external drive</li>

</ul>

<p>Headphones, to check recording quality</p>

</div>

<div id="equipment-1" class="slide section level2">

<h1>Equipment</h1>

<p>External microphones can increase the quality of acoustic data by recording less echo and background noise</p>

<ul>

<li>Look for <strong>cardioid</strong> or <strong>unidirectional</strong> in the description if you are recording single speakers</li>

<li>Recording public events may require an <strong>omnidirectional</strong> microphone</li>

</ul>

<p>An acoustic baffle can reduce echo</p>

<ul>

<li>Soft, fluffy objects: blankets, sofas, etc.</li>

<li>This can also be achieved by selecting the recording setting carefully, and using a cardioid microphone</li>

</ul>

</div>

<div id="other-tips" class="slide section level2">

<h1>Other tips</h1>

<p>Do not use computer noise reduction/filtering in general</p>

<ul>

<li>Go into your computer’s sound settings and <em>turn this off</em>; make sure apps (i.e. Zoom) don’t have separate filters</li>

<li>Normal to hear slight “fuzz” in background, or very slight echo</li>

</ul>

<p>Recording over <strong>Zoom</strong> works surprisingly well, if all else fails <span class="cite">Ge, Mok, &amp; Xiong (2021); Sanker et al (2021)</span></p>

<ul>

<li>Some <em>small</em> effects on the recording are noted</li>

<li>Turn noise cancellation off if using to record (switch to “original sound”)</li>

<li>Better still to use the speaker’s phone on their end to record, and use Zoom to supervise the process</li>

</ul>

</div>



<div id="basic-praat-tutorial" class="title-slide slide section level1">

<h1>Basic Praat (tutorial)</h1>



</div>

<div id="downloading-and-configuring" class="slide section level2">

<h1>Downloading and configuring</h1>

<p>Download Praat from <a href="https://fon.hum.uva.nl">fon.hum.uva.nl</a> or <a href="https://praat.org">praat.org</a></p>

<p><img src="./assets/media/praat1.png" width="800"></p>

<ul>

<li>Mac: the .dmg file contains Praat.app (which you can run immediately) and the option to install</li>

<li>If you have issues opening, see <a href="https://www.fon.hum.uva.nl/praat/download_mac.html">2. “How to Start”</a> here</li>

<li>Windows: the .zip file contains Praat.exe, which you simply double-click to run (instructions <a href="https://www.fon.hum.uva.nl/praat/download_win.html">here</a> if needed)</li>

</ul>

</div>

<div id="windows-and-manual" class="slide section level2">

<h1>Windows and manual</h1>

<p>Both the <strong>object window</strong> (shown below) and <strong>picture window</strong> appear when you open Praat (we’ll ignore the picture window for now)</p>

<p>Basic issues can often be solved using the manual</p>

<p><img src="./assets/media/praat-manual.png" width="400"> <img src="./assets/media/praat-manual-search.png" width="400"></p>

<ul>

<li>The manual is also available online <a href="https://www.fon.hum.uva.nl/praat/manual/Manual.html">here</a></li>

<li>Other introductory guides can be found <a href="https://www.fon.hum.uva.nl/praat/manualsByOthers.html">here</a></li>

</ul>

</div>

<div id="first-recording" class="slide section level2">

<h1>First recording</h1>

<p>Let’s record ourselves saying a “good day, good afternoon” greeting in whichever language you would like</p>

<p><img src="./assets/media/praat-record-menu.png" width="400"> <img src="./assets/media/praat-record-console.png" width="400"></p>

<ul>

<li>Make sure you “save to list” before closing the recorder!</li>

</ul>

</div>

<div id="stored-sound" class="slide section level2">

<h1>Stored sound</h1>

<p>You should now have a Sound in your <strong>objects</strong> window</p>

<ul>

<li>Select the Sound object and a menu will appear to the right</li>

<li>Click “Play” to hear your sound</li>

</ul>

<p><img src="./assets/media/praat-Sound.png" width="600"></p>

</div>

<div id="saving-your-recording" class="slide section level2">

<h1>Saving your recording</h1>

<p>We’ll end this by saving our work as a .WAV file (the standard format for phonetics work)</p>

<ul>

<li>The file is not yet saved, only <em>stored</em> in Praat</li>

<li>If you close Praat without saving the file, it will vanish</li>

</ul>

<p><img src="./assets/media/praat-save-Sound.png" width="600"></p>

</div>

<div id="importing-a-sound-file" class="slide section level2">

<h1>Importing a sound file</h1>

<audio id="bush" src="./assets/media/bbk-hills-of-bushes.wav">

</audio>

<p>We might also <strong>import</strong> sounds which have already been recorded</p>

<ul>

<li>Download <a href="./assets/media/bbk-files.zip">this ZIP file</a> (673 KB), which contains all of the files we’ll use</li>

<li>Use the “Open” dialogue to open <strong>bbk-hills-of-bushes.wav</strong></li>

<li>That file contains one utterance of Babanki <button onclick="document.getElementById('bush').play()"> [tə̀tāŋ tə́ tə́ꜜtóʔ]</button> “hills of bushes” <span class="cite">from Faytak &amp; Akumbu (2021)</span></li>

</ul>

<p><img src="./assets/media/praat-import.png" width="600"></p>

</div>



<div id="making-and-using-textgrids" class="title-slide slide section level1">

<h1>Making and using TextGrids</h1>



</div>

<div id="viewing-a-sound-file" class="slide section level2">

<h1>Viewing a sound file</h1>

<p>We’ll start by viewing Babanki <button onclick="document.getElementById('bush').play()"> [tə̀tāŋ tə́ tə́ꜜtóʔ]</button> “hills of bushes”</p>

<ul>

<li>Select the Sound and click “View and Edit” in the right menu</li>

</ul>

<p>Viewer window has button and keyboard controls</p>

<ul>

<li>Select by clicking, SHIFT-clicking, or clicking and dragging in sound</li>

<li>Press TAB to play selected sound, or click bar below window</li>

<li>Control buttons (zoom in, zoom out, scroll) are at lower left</li>

<li>Keyboard shortcuts: CTRL+ (PC) or Command+ (Mac)…

<ul>

<li>A: zoom out to all</li>

<li>N: zoom to selection</li>

<li>I: zoom in</li>

<li>O: zoom out</li>

</ul></li>

</ul>

<p><img src="./assets/media/praat-bbk-open.png" width="700"></p>

<p>We may wish to know where the words and segments are, but we lack useful landmarks at this point</p>

<ul>

<li>Each “blob” is a syllable</li>

<li>No indication of tones (yet)</li>

</ul>

</div>

<div id="making-a-textgrid" class="slide section level2">

<h1>Making a TextGrid</h1>

<p><strong>TextGrids</strong> are one of the most useful features of Praat: annotate and organize your audio files</p>

<ul>

<li>Using the menu as shown below, we’ll make a TextGrid for our Babanki sound object</li>

</ul>

<p><img src="./assets/media/praat-annotate.png" width="400"> <img src="./assets/media/praat-make-tg.png" width="400"></p>

</div>

<div id="interval-tiers" class="slide section level2">

<h1>Interval tiers</h1>

<p>Let’s use the <strong>interval tier</strong> “sentence” and use it to transcribe the utterance</p>

<ul>

<li>Contains a list of ranges in time separated by boundaries</li>

<li>Useful for marking off words, utterances, and some vowels and consonants</li>

<li>Here, click before the beginning and after the end of the utterance, then type a transcription or translation in the middle</li>

</ul>

<p><img src="./assets/media/praat-bbk-interval.png" width="700"></p>

</div>

<div id="point-tiers" class="slide section level2">

<h1>Point tiers</h1>

<p>Let’s use the <strong>point tier</strong> “stop” to mark off where each [t] release happens</p>

<ul>

<li>Contains a list of points in time</li>

<li>Useful for instantaneous events</li>

<li>Note that <em>intervals are generally more useful</em> for most segments</li>

<li>Can’t click and highlight range like interval tier</li>

</ul>

<p><img src="./assets/media/praat-bbk-point.png" width="700"></p>

</div>

<div id="adding-and-removing-tiers" class="slide section level2">

<h1>Adding and removing tiers</h1>

<p>We might be dissatisfied with how the tone marks are displaying; we could make a new tier for tones (autosegmental style)</p>

<p><img src="./assets/media/praat-bbk-add.png" width="400"> <img src="./assets/media/praat-bbk-add2.png" width="300"></p>

<p>Amending the TextGrid using the new tier:</p>

<p><img src="./assets/media/praat-bbk-add3.png" width="700"></p>

</div>

<div id="saving-textgrids" class="slide section level2">

<h1>Saving TextGrids</h1>

<p>Using CTRL+S or the menu shown below, you must <em>save</em> your TextGrid when you are done</p>

<ul>

<li>If you close Praat without saving your TextGrid, it will vanish</li>

<li>Much like recorded audio files which are stored in the object list</li>

</ul>

<p><img src="./assets/media/praat-tg-save.png" width="700"></p>

</div>



<div id="reading-our-data" class="title-slide slide section level1">

<h1>Reading our data</h1>



</div>

<div id="data-displays" class="slide section level2">

<h1>Data displays</h1>

<p>We may wish to provide further details in our TextGrids, but we encounter another problem here: how to interpret the data?</p>

<ul>

<li>Praat shows <strong>waveforms</strong> and <strong>spectrograms</strong></li>

<li>Note the simpler TextGrid (segments, tones); <strong>bbk-hills-of-bushes.TextGrid</strong> in downloaded files</li>

</ul>

<p><img src="./assets/media/praat-bbk-datatypes.png" width="700"></p>

</div>

<div id="waveforms" class="slide section level2">

<h1>Waveforms</h1>

<p><strong>Waveforms</strong> show sound pressure (the pressure that sound waves make on the microphone) versus time</p>

<ul>

<li>We expect any <strong>voiced</strong> speech signal to <em>oscillate</em> because the vocal folds open and close in a repeating pattern</li>

<li>Other <strong>voiceless</strong> sounds show no movement away from “zero line” and no clear oscillation</li>

</ul>

<p><img src="./assets/media/praat-bbk-periodicity.png" width="700"></p>

</div>

<div id="sonority" class="slide section level2">

<h1>Sonority</h1>

<p>Sounds produced with a more open mouth are <em>louder</em> and more sonorous <span class="cite">Parker (2008) </span>; these are <em>thicker</em> on the waveform</p>

<p><img src="./assets/media/praat-bbk-sonority.png" width="700"></p>

</div>

<div id="spectrograms" class="slide section level2">

<h1>Spectrograms</h1>

<p>We can also show the <strong>spectrogram</strong> for our recording</p>

<ul>

<li>Breaks down our waveform to give us information about the <strong>sound spectrum</strong> and where its energy is (high or low frequency)</li>

</ul>

<p>Spectrograms are three-dimensional, and show time vs. <strong>frequency</strong> vs. sound pressure (color)</p>

<ul>

<li>The darker the spectrogram (and the thicker the waveform), the more sound pressure there is</li>

</ul>

<p><img src="./assets/media/praat-bbk-spectro0.png" width="700"></p>

<ul>

<li>Think of it as an elevation map (Mt. Cameroon pictured)</li>

</ul>

<p><img src="./assets/media/relief-map.png" width="400"></p>

</div>

<div id="interpreting-spectrograms" class="slide section level2">

<h1>Interpreting spectrograms</h1>

<p><strong>Vowels</strong>, <strong>semivowels</strong>, and <strong>approximants</strong> have characteristic striping, horizontally and vertically</p>

<ul>

<li>Voicing is visible as vertical stripes in vowels, and as a small “bar” at bottom</li>

<li><strong>Formants</strong> are clear horizontal bands above the voicing bar</li>

</ul>

<p><img src="./assets/media/praat-bbk-spectro1.png" width="700"></p>

</div>

<div id="interpreting-spectrograms-1" class="slide section level2">

<h1>Interpreting spectrograms</h1>

<p><strong>Nasals</strong> look somewhat like vowels, with “smudged” formants and less energy (darkness)</p>

<ul>

<li>Due to the opening of the velum: nasal cavity “muffles” the sound</li>

<li>Much like soft objects in a room muffle echo</li>

</ul>

<p><img src="./assets/media/praat-bbk-spectro2.png" width="700"></p>

</div>

<div id="interpreting-spectrograms-2" class="slide section level2">

<h1>Interpreting spectrograms</h1>

<p><strong>Fricatives</strong> have high-frequency or low-frequency noise</p>

<ul>

<li>Dark irregular smudges across entire areas of spectrogram</li>

<li>The further back the fricative, the lower the average frequency</li>

<li>Compare [s] and [ʒ]: [s] is further front, has higher frequency, sits higher on spectrogram</li>

</ul>

<p><img src="./assets/media/praat-fricative1.png" width="700"></p>

<p><img src="./assets/media/praat-fricative2.png" width="700"></p>

</div>

<div id="interpreting-spectrograms-3" class="slide section level2">

<h1>Interpreting spectrograms</h1>

<p><strong>Stops</strong> show an absence of (most) energy followed by a <strong>burst</strong> across the whole spectrum</p>

<p><img src="./assets/media/praat-bbk-stop1.png" width="700"></p>

<p><strong>Affricates</strong> look similar, but as if they were followed by a fricative</p>

<ul>

<li>From Babanki [kə̀dʒóm] ‘Babanki’ <span class="cite">Faytak &amp; Akumbu (2021)</span></li>

</ul>

<p><img src="./assets/media/praat-bbk-stop2.png" width="700"></p>

</div>

<div id="prenasalized-segments" class="slide section level2">

<h1>Prenasalized segments</h1>

<p>Prenasalized stops and affricates often have a <em>long nasal closure</em> followed by a <em>short oral closure</em> which we can see clearly in the spectrogram</p>

<ul>

<li>Note the “smudged” energy goes away when oral closure begins in [ⁿpfʲ] below</li>

<li>From Babanki [kə̀ⁿpfʲɨ́ŋ] ‘owl’ <span class="cite">Faytak &amp; Akumbu (2021)</span></li>

</ul>

<p><img src="./assets/media/praat-bbk-stop3.png" width="700"></p>

</div>



<div id="drawing-figures" class="title-slide slide section level1">

<h1>Drawing figures</h1>



</div>

<div id="why-make-figures" class="slide section level2">

<h1>Why make figures?</h1>

<p>Figures are an easy way to present a small amount of phonetic data in scientific papers</p>

<ul>

<li>Give support to phonological judgments</li>

<li>Support particular transcriptions</li>

<li>Provide more detail for any especially unusual sounds or sound contrasts</li>

</ul>

<p>This section: professional-looking and informative data displays</p>

</div>

<div id="picture-window" class="slide section level2">

<h1>Picture window</h1>

<p>Waveforms and spectrograms can be “drawn” or “painted” (respectively) in the <strong>picture window</strong></p>

<ul>

<li>This also opened when you open Praat; we’ll stop ignoring it now</li>

<li>The blue rectangle indicates the <em>plot area</em> where the figure will be drawn: change size by clicking and dragging as needed</li>

</ul>

<p><img src="./assets/media/praat-picture.png" width="600"></p>

</div>

<div id="drawing-a-waveform" class="slide section level2">

<h1>Drawing a waveform</h1>

<p>“Draw” (in the object window) is for any line-based drawings, including waveforms</p>

<ul>

<li>Select a Sound to draw its waveform</li>

</ul>

<p><img src="./assets/media/praat-bbk-draw.png" width="400"> <img src="./assets/media/praat-draw-options.png" width="500"></p>

<p>The result: a waveform drawn within the plot area</p>

<p><img src="./assets/media/praat-drawn.png" width="600"></p>

</div>

<div id="drawing-a-textgrid" class="slide section level2">

<h1>Drawing a TextGrid</h1>

<p>TextGrids can be drawn as well, using the same menu as Sounds</p>

<ul>

<li>By default, they appear with an empty space above them</li>

</ul>

<p><img src="./assets/media/praat-drawn-tg.png" width="700"></p>

</div>

<div id="combining-textgrids-and-waveforms" class="slide section level2">

<h1>Combining TextGrids and waveforms</h1>

<p>A Sound and TextGrid can be drawn together very easily: simply <strong>select both</strong> and choose the Draw menu as before</p>

<ul>

<li>Adds TextGrid annotation to the waveform drawing</li>

</ul>

<p><img src="./assets/media/praat-drawn-soundtg.png" width="700"></p>

</div>

<div id="extracting-a-spectrogram" class="slide section level2">

<h1>Extracting a spectrogram</h1>

<p>“Paint” is for drawing spectrograms and other objects, but: we need the right <strong>object</strong> to do this</p>

<ul>

<li>Select Sound and click “View and Edit”</li>

<li>Select from the Spectrum menu “Extract visible spectrogram”</li>

</ul>

<p><img src="./assets/media/praat-extract-spec.png" width="700"></p>

</div>

<div id="painting-a-spectrogram" class="slide section level2">

<h1>Painting a spectrogram</h1>

<p>This sends a Spectrogram object to the object list; when we select this we get a “Paint” option under Draw</p>

<p><img src="./assets/media/praat-bbk-paint.png" width="400"> <img src="./assets/media/praat-paint-options.png" width="500"></p>

<p>The result: as expected, but a bit too tall for its width (make plot area wider/shorter)</p>

<p><img src="./assets/media/praat-painted.png" width="700"></p>

</div>

<div id="spectrograms-and-textgrids" class="slide section level2">

<h1>Spectrograms and TextGrids</h1>

<p>Drawing a spectrogram and a TextGrid at the same time is a bit more complicated</p>

<ol style="list-style-type: decimal">

<li>Paint the spectrogram, but <strong>uncheck “Garnish”</strong></li>

<li>Add the Y axis marks using the “Margins” menu</li>

</ol>

<p><img src="./assets/media/praat-marksleft.png" width="400"> <img src="./assets/media/praat-yaxis.png" width="400"></p>

<ol start="3" style="list-style-type: decimal">

<li>Add a Y axis label, usually “Frequency (Hz)”</li>

</ol>

<ul>

<li>I’ve also added a box around the plot here with “Margins” &gt; “Draw Inner Box”</li>

</ul>

<p><img src="./assets/media/praat-textleft.png" width="400"> <img src="./assets/media/praat-axistext.png" width="400"></p>

</div>

<div id="spectrograms-and-textgrids-1" class="slide section level2">

<h1>Spectrograms and TextGrids</h1>

<ol start="3" style="list-style-type: decimal">

<li><strong>Resize</strong> plot area to be taller than spectrogram (pictured), and Draw the TextGrid</li>

</ol>

<p><img src="./assets/media/praat-pretg.png" width="600"></p>

<p>The result: TextGrid annotations on top of the spectrogram</p>

<p><img src="./assets/media/praat-painted-tg.png" width="600"></p>

</div>

<div id="saving" class="slide section level2">

<h1>Saving</h1>

<p>As with everything else in Praat, you must <strong>save</strong> before closing the picture window or you will lose your work</p>

<ul>

<li>If you don’t keep the plot area in the same place (covering your figure or margins), you won’t save the entire figure</li>

</ul>

<p><img src="./assets/media/praat-save-picture.png" width="600"></p>

</div>



<div id="measuring-phonetic-properties" class="title-slide slide section level1">

<h1>Measuring phonetic properties</h1>



</div>

<div id="why-numerical-measurements" class="slide section level2">

<h1>Why numerical measurements?</h1>

<p>Now we’ll turn to <strong>taking numerical measurements</strong> in Praat</p>

<ul>

<li>Actual calculation</li>

<li>Displaying <strong>figures</strong> of these measurements</li>

<li>Storing measurements as <strong>tabular data</strong> (at the end)</li>

</ul>

<p>More than showing an entire sound file as a waveform or spectrogram, focusing on a specific phonetic property can be useful</p>

<ul>

<li>Make a figure for this specific property</li>

<li>Focus on topic of interest for your discussion</li>

<li>Display with a TextGrid, a waveform, etc.</li>

</ul>

</div>

<div id="why-numerical-measurements-1" class="slide section level2">

<h1>Why numerical measurements?</h1>

<p>Also lets us measure many utterances and <strong>summarize</strong>, which also allows us to handle <strong>phonetic variation</strong></p>

<ul>

<li>Languages differ in their phonetic implementation of the “same” segments</li>

<li>Speakers of the same language produce it differently depending on their history, social stance, etc</li>

<li>Even phonologically identical words can differ slightly phonetically <span class="cite">Gahl (2008)</span></li>

</ul>

<p>Because of this it’s best to collect <strong>many observations</strong> and <strong>average</strong> or <strong>model</strong> the data to remove noise and variation</p>

<ul>

<li>Multiple speakers</li>

<li>Multiple repetitions</li>

<li>Multiple words</li>

</ul>

</div>

<div id="duration" class="slide section level2">

<h1>Duration</h1>

<p>One of the simplest measures: <strong>duration</strong> of segments or words</p>

<ul>

<li>Simply ending time of the interval minus its starting time (<span class="math inline"><em>t</em><sub>2</sub> − <em>t</em><sub>1</sub></span>), in seconds</li>

<li>Two ways to acquire this in Praat:

<ul>

<li>Displayed in viewing window when you select an interval</li>

<li>If you use the “Query” menu, a text box appears which you can copy-paste the value from</li>

</ul></li>

</ul>

<p><img src="./assets/media/praat-bbk-duration.png" width="700"></p>

</div>

<div id="practical-use" class="slide section level2">

<h1>Practical use</h1>

<p>Duration of segments, subsegments</p>

<p>Laryngeal contrasts (how long is aspiration of stop), gemination, vowel length, etc.</p>

<p>Pius data?</p>

</div>

<div id="pitch-fundamental-frequency-f0" class="slide section level2">

<h1>Pitch (fundamental frequency, f0)</h1>

<ul>

<li>Turn on “show pitch”; query pitch (f0)</li>

</ul>

<p><img src="./assets/media/praat-pitch-menu.png" width="700"></p>

</div>

<div id="practical-use-1" class="slide section level2">

<h1>Practical use</h1>

<p>f0 signals pitch (tone) - all sorts of phenomena</p>

<ul>

<li>Downstep, downdrift, pitch reset, lexical tone contrasts, intonation, etc</li>

</ul>

<p>intensity is useful for a range of properties (cons lenition, stress, etc)</p>

<p>Pius example:</p>

<ul>

<li>Change defaults to 70-140 Hz to reflect speaker’s pitch range</li>

</ul>

</div>

<div id="intensity" class="slide section level2">

<h1>Intensity</h1>

<p>Exactly parallel for intensity</p>

<p><img src="./assets/media/praat-intensity-menu.png" width="700"></p>

</div>

<div id="practical-use-2" class="slide section level2">

<h1>Practical use</h1>

<p>Pius examples</p>

</div>

<div id="f0-and-intensity-figures" class="slide section level2">

<h1>f0 and intensity figures</h1>

<p>f0 and intensity tracks can be added to figures</p>

<ul>

<li>Best to put above/below a spectrogram or waveform</li>

<li>Shown below: pitch contour</li>

</ul>

</div>

<div id="formant-frequencies" class="slide section level2">

<h1>Formant frequencies</h1>

<p>Formant frequencies provide <strong>vowel quality</strong> and other contrasts</p>

<ul>

<li>F1 inversely relates to height</li>

<li>F2 inversely relates to backness</li>

<li>F3 directly relates to retroflexion, etc.</li>

</ul>

<p>Formant transitions; lateral and nasal quality, etc.</p>

<p><img src="./assets/media/praat-formant-menu.png" width="700"></p>

</div>

<div id="how-to" class="slide section level2">

<h1>How to</h1>

<p>Turn on “show formants”</p>

<p>Query formant listing</p>

</div>

<div id="formant-estimation" class="slide section level2">

<h1>Formant estimation</h1>

<p>Unlike the other measures, formant estimation often requires calibration to individual speakers</p>

<ul>

<li>Speakers with low f0 need different settings compared to speakers with higher f0</li>

<li>Children (with very high f0) can be especially difficult</li>

<li>Often, different settings are needed for front and back vowels (especially back rounded vowels)</li>

</ul>

<p>Adjust ceiling, adjust number of formants</p>

</div>

<div id="formant-figures" class="slide section level2">

<h1>Formant figures</h1>

<p>Formants work best in an F1-F2 plot (which is not made in Praat), but formant tracks can be drawn like any other measure</p>

</div>

<div id="voicing-pulses" class="slide section level2">

<h1>Voicing (“Pulses”)</h1>

<p><img src="./assets/media/praat-pulse-menu.png" width="700"></p>

</div>

<div id="voicing-report" class="slide section level2">

<h1>Voicing report</h1>

<p><img src="./assets/media/praat-voice-report.png" width="700"></p>

</div>

<div id="practical-use-3" class="slide section level2">

<h1>Practical use</h1>

</div>

<div id="tabular-data" class="slide section level2">

<h1>Tabular data</h1>

<p>The way numerical measurements are stored is important: store as <strong>tabular data</strong> (i.e. spreadsheets)</p>

<ul>

<li>One observation (time point, tone, segment, etc) per row</li>

<li>One measure per column

<ul>

<li>Can have multiple measures per time point</li>

</ul></li>

<li>Name columns using the first row</li>

<li>Use more columns to provide other background information (speaker’s ID, segment or word, experimental condition, etc)</li>

</ul>

<p>Can use Excel or Google Drive (.xls, .txt, or .csv format)</p>

<ul>

<li>Manually building the tabular data in Excel is slow, but it works and requires no new skills</li>

<li>Google Sheets provides a free alternative to Excel, but data transfer might be expensive</li>

<li><strong>Praat scripting</strong> can quickly produce tabular data, but some new skills required, beyond the scope of this tutorial</li>

</ul>

</div>

<div id="example" class="slide section level2">

<h1>Example</h1>

<p>…</p>

<p>how to paste easily? Praat adds three spaces (instead of a tab) between measurement columns, so each row is read as a single string</p>

<p>Google Docs can get around this:</p>

<p><img src="./assets/media/gdocs-split-cols.png" width="700"></p>

</div>

<div id="references" class="slide section level2 bib">

<h1 class="bib">References</h1>

<p>Faytak, M., &amp; Akumbu, P. W. (2021). Kejom (Babanki). <em>Journal of the International Phonetic Association</em>, 51(2), 333-354. <a href="https://doi.org/10.1017/S0025100319000264">Article</a></p>

<p>Gahl, S. (2008). <em>Time</em> and <em>Thyme</em> Are not Homophones: The Effect of Lemma Frequency on Word Durations in Spontaneous Speech. <em>Language</em> 84(3), 474-496. <a href="https://doi.org/10.1353/lan.0.0035">Article</a></p>

<p>Ge, C., Xiong, Y., &amp; Mok, P. (2021). How reliable are phonetic data collected remotely? Comparison of recording devices and environments on acoustic measurements. In <em>Proc Interspeech 2021</em>, 1683-1687. <a href="http://ling.cuhk.edu.hk/people/peggy/GeXiongMok_Interspeech2021.pdf">PDF</a></p>

<p>Hyman, L. (2014). How to study a tone language. <em>Language Documentation &amp; Conservation</em>, 8, 525-562. <a href="https://scholarspace.manoa.hawaii.edu/handle/10125/24624">Article</a></p>

<p>Parker, S. (2008). Sound level protrusions as physical correlates of sonority. <em>Journal of Phonetics</em>, 36(1), 55-90. <a href="https://doi.org/10.1016/j.wocn.2007.09.003">Abstract</a></p>

<p>Sanker, C., Babinski, S., Burns, R., Evans, M., Johns, J., Kim, J., Smith, S., Weber, N., &amp; Bowern, C. (2021). (Don’t) try this at home! The effects of recording devices and software on phonetic analysis. <em>Language</em>, 97(4), e360-e382. <a href="https://muse.jhu.edu/article/840967/pdf">PDF</a></p>

<p>Zee, E. (1981). Effect of vowel quality on perception of post–vocalic nasal consonants in noise. <em>Journal of Phonetics</em>, 9(1), 35-48. <a href="https://doi.org/10.1016/S0095-4470(19)30925-8">Abstract</a></p>

</div>

</body>

</html>
